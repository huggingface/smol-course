# Parameter-Efficient Fine-Tuning (PEFT)

Khi c√°c m√¥ h√¨nh ng√¥n ng·ªØ ng√†y c√†ng l·ªõn, vi·ªác tinh ch·ªânh theo c√°ch truy·ªÅn th·ªëng tr·ªü n√™n ng√†y c√†ng kh√≥ khƒÉn. Vi·ªác c·∫≠p nh·∫≠t to√†n b·ªô m·ªôt m√¥ h√¨nh v·ªõi h√†ng t·ª∑ tham s·ªë ƒë√≤i h·ªèi m·ªôt l∆∞·ª£ng l·ªõn b·ªô nh·ªõ GPU, t·ªën k√©m chi ph√≠ l∆∞u tr·ªØ c√°c phi√™n b·∫£n tinh ch·ªânh, v√† th·∫≠m ch√≠ c√≥ th·ªÉ l√†m gi·∫£m kh·∫£ nƒÉng kh√°i qu√°t h√≥a ban ƒë·∫ßu c·ªßa m√¥ h√¨nh. Ph∆∞∆°ng ph√°p Tinh ch·ªânh Hi·ªáu qu·∫£ Tham s·ªë (Parameter-Efficient Fine-Tuning - PEFT) xu·∫•t hi·ªán nh∆∞ m·ªôt gi·∫£i ph√°p nh·∫±m gi·∫£i quy·∫øt c√°c th√°ch th·ª©c n√†y, b·∫±ng c√°ch ch·ªâ ƒëi·ªÅu ch·ªânh m·ªôt t·∫≠p h·ª£p nh·ªè tham s·ªë c·ªßa m√¥ h√¨nh trong khi gi·ªØ nguy√™n ph·∫ßn l·ªõn tham s·ªë ban ƒë·∫ßu.

Trong khi tinh ch·ªânh truy·ªÅn th·ªëng ƒë√≤i h·ªèi ph·∫£i c·∫≠p nh·∫≠t to√†n b·ªô tham s·ªë c·ªßa m√¥ h√¨nh trong qu√° tr√¨nh hu·∫•n luy·ªán, c√°c ph∆∞∆°ng ph√°p PEFT ch·ªâ y√™u c·∫ßu ƒëi·ªÅu ch·ªânh d∆∞·ªõi 1% s·ªë tham s·ªë c·ªßa m√¥ h√¨nh g·ªëc. C√°ch ti·∫øp c·∫≠n n√†y mang l·∫°i nh·ªØng l·ª£i √≠ch v∆∞·ª£t tr·ªôi:

- Cho ph√©p fine-tuning tr√™n ph·∫ßn c·ª©ng ph·ªï th√¥ng v·ªõi b·ªô nh·ªõ GPU h·∫°n ch·∫ø.
- T·ªëi ∆∞u h√≥a vi·ªác l∆∞u tr·ªØ, d·ªÖ d√†ng qu·∫£n l√Ω nhi·ªÅu m√¥ h√¨nh th√≠ch ·ª©ng cho t·ª´ng t√°c v·ª• c·ª• th·ªÉ.
- C·∫£i thi·ªán kh·∫£ nƒÉng t·ªïng qu√°t h√≥a trong c√°c t√¨nh hu·ªëng d·ªØ li·ªáu h·∫°n ch·∫ø.
- R√∫t ng·∫Øn ƒë√°ng k·ªÉ th·ªùi gian hu·∫•n luy·ªán v√† ƒë√°nh gi√°.

## C√°c ph∆∞∆°ng ph√°p ph·ªï bi·∫øn

In this module, we will cover two popular PEFT methods:

### 1Ô∏è‚É£ LoRA (Low-Rank Adaptation)

LoRA ƒë√£ tr·ªü th√†nh ph∆∞∆°ng ph√°p PEFT ƒë∆∞·ª£c √°p d·ª•ng r·ªông r√£i nh·∫•t, mang l·∫°i m·ªôt gi·∫£i ph√°p tinh t·∫ø cho vi·ªác th√≠ch nghi m√¥ h√¨nh hi·ªáu qu·∫£. Thay v√¨ ch·ªânh s·ª≠a to√†n b·ªô m√¥ h√¨nh, **LoRA ch√®n th√™m c√°c ma tr·∫≠n c√≥ th·ªÉ hu·∫•n luy·ªán v√†o c√°c l·ªõp attention c·ªßa m√¥ h√¨nh**. Ph∆∞∆°ng ph√°p n√†y th∆∞·ªùng gi√∫p gi·∫£m kho·∫£ng 90% s·ªë l∆∞·ª£ng tham s·ªë c·∫ßn hu·∫•n luy·ªán, ƒë·ªìng th·ªùi v·∫´n duy tr√¨ hi·ªáu su·∫•t t∆∞∆°ng ƒë∆∞∆°ng v·ªõi vi·ªác fine-tuning to√†n b·ªô m√¥ h√¨nh. Ch√∫ng ta s·∫Ω t√¨m hi·ªÉu chi ti·∫øt v·ªÅ LoRA trong m·ª•c [LoRA (Low-Rank Adaptation)](./lora_adapters.md).
 
### 2Ô∏è‚É£ Tinh ch·ªânh Prompt

Prompt tuning cung c·∫•p m·ªôt c√°ch ti·∫øp c·∫≠n **nh·∫π nh√†ng** h∆°n n·ªØa b·∫±ng c√°ch **th√™m c√°c token c√≥ th·ªÉ hu·∫•n luy·ªán** v√†o ƒë·∫ßu v√†o thay v√¨ ch·ªânh s·ª≠a tr·ªçng s·ªë c·ªßa m√¥ h√¨nh. M·∫∑c d√π prompt tuning √≠t ph·ªï bi·∫øn h∆°n so v·ªõi LoRA, nh∆∞ng ƒë√¢y v·∫´n l√† m·ªôt k·ªπ thu·∫≠t h·ªØu √≠ch ƒë·ªÉ nhanh ch√≥ng th√≠ch nghi m√¥ h√¨nh v·ªõi c√°c nhi·ªám v·ª• ho·∫∑c lƒ©nh v·ª±c m·ªõi. Ch√∫ng ta s·∫Ω kh√°m ph√° prompt tuning trong m·ª•c [Prompt Tuning](./prompt_tuning.md) 

## B√†i t·∫≠p

| Ti√™u ƒë·ªÅ | M√¥ t·∫£ | B√†i t·∫≠p | ƒê∆∞·ªùng d·∫´n | Colab |
|-------|-------------|----------|------|-------|
| LoRA Fine-tuning | T√¨m hi·ªÉu c√°ch Fine-tune m√¥ h√¨nh s·ª≠ d·ª•ng LoRA | üê¢ Hu·∫•n luy·ªán m√¥ h√¨nh s·ª≠ d·ª•ng LoRA<br>üêï Th·ª≠ nghi·ªám v·ªõi nhi·ªÅu gi√° tr·ªã h·∫°ng kh√°c nhau<br>ü¶Å So s√°nh hi·ªáu qu·∫£ v·ªõi fine-tune to√†n b·ªô | [Notebook](./notebooks/finetune_sft_peft.ipynb) | <a target="_blank" href="https://colab.research.google.com/github/huggingface/smol-course/blob/main/3_parameter_efficient_finetuning/notebooks/finetune_sft_peft.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a> |  
| Load LoRA Adapters | T√¨m hi·ªÉu c√°ch t·∫£i v√† s·ª≠ d·ª•ng c√°c LoRA adapter ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán | üê¢ T·∫£i adapter ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán tr∆∞·ªõc<br>üêï G·ªôp adapter v·ªõi m√¥ h√¨nh g·ªëc<br>ü¶Å Chuy·ªÉn ƒë·ªïi gi·ªØa nhi·ªÅu adapter | [Notebook](./notebooks/load_lora_adapter.ipynb) | <a target="_blank" href="https://colab.research.google.com/github/huggingface/smol-course/blob/main/3_parameter_efficient_finetuning/notebooks/load_lora_adapter.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a> |  
<!-- | Prompt Tuning | Learn how to implement prompt tuning | üê¢ Train soft prompts<br>üêï Compare different initialization strategies<br>ü¶Å Evaluate on multiple tasks | [Notebook](./notebooks/prompt_tuning_example.ipynb) | <a target="_blank" href="https://colab.research.google.com/github/huggingface/smol-course/blob/main/3_parameter_efficient_finetuning/notebooks/prompt_tuning_example.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a> | -->

## Resources
- [PEFT Documentation](https://huggingface.co/docs/peft)
- [LoRA Paper](https://arxiv.org/abs/2106.09685)
- [QLoRA Paper](https://arxiv.org/abs/2305.14314)
- [Prompt Tuning Paper](https://arxiv.org/abs/2104.08691)
- [Hugging Face PEFT Guide](https://huggingface.co/blog/peft)
- [How to Fine-Tune LLMs in 2024 with Hugging Face](https://www.philschmid.de/fine-tune-llms-in-2024-with-trl) 
- [TRL](https://huggingface.co/docs/trl/index)
