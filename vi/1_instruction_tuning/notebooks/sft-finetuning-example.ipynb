{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hu·∫•n luy·ªán c√≥ gi√°m s√°t v·ªõi SFTTrainer\n",
    "\n",
    "B√†i h·ªçc n√†y se d·∫°y b·∫°n c√°c hu·∫•n luy·ªán m√¥ h√¨nh `HuggingFaceTB/SmolLM2-135M` b·∫±ng `SFTTrainer` trong th∆∞ vi·ªán `trl`.  C√°c cell trong notebook n√†y s·∫Ω ch·∫°y v√† hu·∫•n luy·ªán m√¥ h√¨nh. B·∫°n c√≥ th·ªÉ ch·ªçn ƒë·ªô kh√≥ b·∫±ng c√°ch th·ª≠ nghi·ªám v·ªõi c√°c b·ªô d·ªØ li·ªáu kh√°c nhau.\n",
    "\n",
    "<div style='background-color: lightblue; padding: 10px; border-radius: 5px; margin-bottom: 20px; color:black'>\n",
    "    <h2 style='margin: 0;color:blue'>B√†i t·∫≠p: Fine-Tuning SmolLM2 v·ªõi SFTTrainer</h2>\n",
    "    <p>Ch·ªçn m·ªôt b·ªô d·ª± li·ªáu t·ª´ Hugging Face hub v√† hu·∫•n luy·ªán m·ªôt m√¥ h√¨nh tr√™n b·ªô d·ªØ li·ªáu ƒë√≥. </p> \n",
    "    <p><b>C√°c b√†i t·∫≠p</b></p>\n",
    "    <p>üê¢ S·ª≠ d·ª•ng b·ªô d·ªØ li·ªáu `HuggingFaceTB/smoltalk`</p>\n",
    "    <p>üêï Th·ª≠ nghi·ªám v·ªõi b·ªô d·ªØ li·ªáu `bigcode/the-stack-smol` v√† hu·∫•n luy·ªán m·ªôt m√¥ h√¨nh sinh code tr√™n t·∫≠p con c·ª• th·ªÉ `data/python`.</p>\n",
    "    <p>ü¶Å Ch·ªçn m·ªôt b·ªô d·ªØ li·ªáu li√™n quan ƒë·∫øn m·ªôt lƒ©nh v·ª±c m√† b·∫°n quan t√¢m</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T02:45:13.747764Z",
     "iopub.status.busy": "2024-12-16T02:45:13.747488Z",
     "iopub.status.idle": "2024-12-16T02:45:24.357921Z",
     "shell.execute_reply": "2024-12-16T02:45:24.357041Z",
     "shell.execute_reply.started": "2024-12-16T02:45:13.747736Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.46.3)\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (3.1.0)\n",
      "Collecting trl\n",
      "  Downloading trl-0.12.2-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (0.26.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.6.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: accelerate>=0.34.0 in /opt/conda/lib/python3.10/site-packages (from trl) (1.1.1)\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from trl) (13.7.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.34.0->trl) (5.9.3)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.34.0->trl) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.6.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->trl) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->trl) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->trl) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.34.0->trl) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.34.0->trl) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.34.0->trl) (3.1.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate>=0.34.0->trl) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate>=0.34.0->trl) (1.3.0)\n",
      "Downloading trl-0.12.2-py3-none-any.whl (365 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m365.7/365.7 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: trl\n",
      "Successfully installed trl-0.12.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "261d960e646849c6b78f5ebcf0110057",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# C√†i ƒë·∫∑t c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt\n",
    "# !pip install transformers datasets trl huggingface_hub\n",
    "\n",
    "# ƒêƒÉng nh·∫≠p v√†o Hugging Face\n",
    "from huggingface_hub import login\n",
    "\n",
    "login()\n",
    "\n",
    "# ƒê·ªÉ thu·∫≠n ti·ªán, b·∫°n c√≥ th·ªÉ t·∫°o m·ªôt bi·∫øn m√¥i tr∆∞·ªùng ch·ª©a `token hub` c·ªßa b·∫°n d∆∞·ªõi d·∫°ng HF_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T02:45:41.791847Z",
     "iopub.status.busy": "2024-12-16T02:45:41.790983Z",
     "iopub.status.idle": "2024-12-16T02:46:10.388202Z",
     "shell.execute_reply": "2024-12-16T02:46:10.387265Z",
     "shell.execute_reply.started": "2024-12-16T02:45:41.791814Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1914b079fbee4eb1b06fed8fa17050f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/704 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90b0b42e98024e50a37ca5f1c34bb00a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/269M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ade3519bb81f4c4d9024ffcac8426151",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08ad74424d9940678fbb4bd37ff446a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/3.66k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a0d5fb3f71a4861831bd4abccfe2f8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/801k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2ce6155d48a4126b1dd1295a81e4c98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bebcd3e91904d55ae365027741deb9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.10M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "590952add9054fbc810663d28bdbc01d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/831 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# C√°c th∆∞ vi·ªán c·∫ßn thi·∫øt\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from trl import SFTConfig, SFTTrainer, setup_chat_format\n",
    "import torch\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    ")\n",
    "\n",
    "# T·∫£i m√¥ h√¨nh v√† tokenizer\n",
    "model_name = \"HuggingFaceTB/SmolLM2-135M\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    pretrained_model_name_or_path=model_name\n",
    ").to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=model_name)\n",
    "\n",
    "# Thi·∫øt l·∫≠p ƒë·ªãnh d·∫°ng chat\n",
    "model, tokenizer = setup_chat_format(model=model, tokenizer=tokenizer)\n",
    "\n",
    "# ƒê·∫∑t t√™n cho m√¥ h√¨nh hu·∫•n luy·ªán ƒë·ªÉ l∆∞u &/ t·∫£i l√™n\n",
    "finetune_name = \"SmolLM2-FT-everyday\"\n",
    "finetune_tags = [\"smol-course\", \"module_1\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sinh vƒÉn b·∫£n v·ªõi M√¥ h√¨nh g·ªëc\n",
    "\n",
    "·ªû ƒë√¢y ch√∫ng ta s·∫Ω th·ª≠ nghi·ªám m√¥ h√¨nh g·ªëc ch∆∞a ƒë∆∞·ª£c hu·∫•n luy·ªán tr√™n ƒë·ªãnh d·∫°ng chat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T02:46:10.389859Z",
     "iopub.status.busy": "2024-12-16T02:46:10.389582Z",
     "iopub.status.idle": "2024-12-16T02:46:14.594220Z",
     "shell.execute_reply": "2024-12-16T02:46:14.593378Z",
     "shell.execute_reply.started": "2024-12-16T02:46:10.389833Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training:\n",
      "user\n",
      "Write a haiku about programming\n",
      "Write a haiku about programming\n",
      "Write a haiku about programming\n",
      "Write a haiku about programming\n",
      "Write a haiku about programming\n",
      "Write a haiku about programming\n",
      "Write a haiku about programming\n",
      "Write a haiku about programming\n",
      "Write a haiku about programming\n",
      "Write a haiku about programming\n",
      "Write a haiku about programming\n",
      "Write a haiku about programming\n",
      "Write a haiku about programming\n",
      "Write a haiku about programming\n",
      "Write a haiku about programming\n",
      "Write a\n"
     ]
    }
   ],
   "source": [
    "# Ki·ªÉm tra m√¥ h√¨nh g·ªëc tr∆∞·ªõc khi hu·∫•n luy·ªán\n",
    "prompt = \"Write a haiku about programming\"\n",
    "\n",
    "# ƒê·ªãnh d·∫°ng\n",
    "messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "formatted_prompt = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "\n",
    "# T·∫°o ph·∫£n h·ªìi t·ª´ m√¥ h√¨nh\n",
    "inputs = tokenizer(formatted_prompt, return_tensors=\"pt\").to(device)\n",
    "outputs = model.generate(**inputs, max_new_tokens=100)\n",
    "print(\"Before training:\")\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chu·∫©n b·ªã d·ªØ li·ªáu\n",
    "\n",
    "Ch√∫ng ta s·∫Ω t·∫£i m·ªôt b·ªô d·ªØ li·ªáu m·∫´u v√† ƒë·ªãnh d·∫°ng n√≥ cho vi·ªác hu·∫•n luy·ªán. B·ªô d·ªØ li·ªáu c·∫ßn ƒë∆∞·ª£c c·∫•u tr√∫c v·ªõi c√°c c·∫∑p ƒë·∫ßu v√†o - ƒë·∫ßu ra, trong ƒë√≥ m·ªói ƒë·∫ßu v√†o l√† m·ªôt ch·ªâ th·ªã v√† ƒë·∫ßu ra l√† ph·∫£n h·ªìi mong ƒë·ª£i t·ª´ m√¥ h√¨nh.\n",
    "\n",
    "**TRL s·∫Ω ƒë·ªãnh d·∫°ng c√°c tin nh·∫Øn ƒë·∫ßu v√†o d·ª±a tr√™n ƒë·ªãnh d·∫°ng chat c·ªßa m√¥ h√¨nh** Ch√∫ng c·∫ßn ƒë∆∞·ª£c bi·ªÉu di·ªÖn d∆∞·ªõi d·∫°ng danh s√°ch c√°c t·ª´ ƒëi·ªÉn v·ªõi c√°c kh√≥a: `role` v√† `content`.\n",
    "\n",
    "**V√≠ d·ª•:**\n",
    "```sh\n",
    "[\n",
    "  {\"role\": \"user\", \"content\": \"Hello, how are you?\"},\n",
    "  {\"role\": \"assistant\", \"content\": \"I'm doing well, thank you! How can I assist you today?\",},\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T02:46:14.595528Z",
     "iopub.status.busy": "2024-12-16T02:46:14.595256Z",
     "iopub.status.idle": "2024-12-16T02:46:17.498178Z",
     "shell.execute_reply": "2024-12-16T02:46:17.497400Z",
     "shell.execute_reply.started": "2024-12-16T02:46:14.595503Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b549a507cb3641f5a3eb07f1f8ecc8aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/9.25k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b7f30ed17974f09922d92dea517d850",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/946k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b935eebd94f949e5a8172d76de837676",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/52.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "558cc8d7425d4f9f94ea9a980bfdfe70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/2260 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97434f11aa464c29839d0c2a15df2307",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/119 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# T·∫£i d·ªØ li·ªáu m·∫´u\n",
    "from datasets import load_dataset\n",
    "\n",
    "# TODO: T·∫£i b·ªô d·ªØ li·ªáu th√¥ng qua vi·ªác ƒëi·ªÅu ch·ªânh c√°c tham s·ªë path v√† name\n",
    "ds = load_dataset(path=\"HuggingFaceTB/smoltalk\", name=\"everyday-conversations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T02:46:17.500900Z",
     "iopub.status.busy": "2024-12-16T02:46:17.500078Z",
     "iopub.status.idle": "2024-12-16T02:46:19.516864Z",
     "shell.execute_reply": "2024-12-16T02:46:19.515901Z",
     "shell.execute_reply.started": "2024-12-16T02:46:17.500859Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79568732fa4241daa980cf4b51b77adc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2260 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5662a5c98e5842188d8b3593c03aed72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/119 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: ü¶Å N·∫øu dataset c·ªßa b·∫°n kh√¥ng ·ªü ƒë·ªãnh d·∫°ng m√† TRL c√≥ th·ªÉ chuy·ªÉn ƒë·ªïi th√†nh ƒë·ªãnh d·∫°ng chat, b·∫°n s·∫Ω c·∫ßn x·ª≠ l√Ω n√≥.\n",
    "# Tham kh·∫£o [ƒê·ªãnh d·∫°ng Chat](../chat_templates.md)\n",
    "\n",
    "def process_dataset(sample):\n",
    "    # TODO: üê¢ Chuy·ªÉn ƒë·ªïi d·ªØ li·ªáu sang ƒë·ªãnh d·∫°ng ChatML\n",
    "    # S·ª≠ d·ª•ng `tokenizer.apply_chat_template` ƒë·ªÉ √°p d·ª•ng ƒë·ªãnh d·∫°ng h·ªôi tho·∫°i\n",
    "    sample = sample.get('messages', [])\n",
    "    sample = tokenizer.apply_chat_template(sample, tokenize=True, add_generation_prompt=True)\n",
    "    return {'text': sample}\n",
    "\n",
    "\n",
    "ds = ds.map(process_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ƒêi·ªÅu ch·ªânh SFTTrainer\n",
    "\n",
    "ƒêi·ªÅu ch·ªânh `SFTTrainer` v·ªõi c√°c tham s·ªë kh√°c nhau gi√∫p ƒëi·ªÅu khi·ªÉn qu√° tr√¨nh hu·∫•n luy·ªán tr·ªü n√™n hi·ªáu qu·∫£ h∆°n. C√°c th√¥ng s·ªë bao g·ªìm\n",
    "- S·ªë b∆∞·ªõc hu·∫•n luy·ªán (steps)\n",
    "- K√≠ch th∆∞·ªõc batch (batch size)\n",
    "- T·ªëc ƒë·ªô h·ªçc (learning rate)\n",
    "- Chi·∫øn l∆∞·ª£c ƒë√°nh gi√° m√¥ h√¨nh (evaluation strategy)\n",
    "\n",
    "Ngo√†i ra, c√≤n r·∫•t nhi·ªÅu th√¥ng s·ªë kh√°c, b·∫°n c√≥ th·ªÉ tham kh·∫£o th√™m ·ªü [SFTTrainer](https://huggingface.co/docs/trl/sft_trainer)\n",
    "\n",
    "ƒêi·ªÅu ch·ªânh c√°c tham s·ªë n√†y d·ª±a tr√™n y√™u c·∫ßu c·ª• th·ªÉ v√† t√†i nguy√™n t√≠nh to√°n c·ªßa b·∫°n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T10:36:21.733432Z",
     "iopub.status.busy": "2024-12-13T10:36:21.733046Z",
     "iopub.status.idle": "2024-12-13T10:36:21.739781Z",
     "shell.execute_reply": "2024-12-13T10:36:21.738982Z",
     "shell.execute_reply.started": "2024-12-13T10:36:21.733390Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['full_topic', 'messages', 'text'],\n",
       "        num_rows: 2260\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['full_topic', 'messages', 'text'],\n",
       "        num_rows: 119\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T02:47:28.486869Z",
     "iopub.status.busy": "2024-12-16T02:47:28.486037Z",
     "iopub.status.idle": "2024-12-16T02:47:29.439009Z",
     "shell.execute_reply": "2024-12-16T02:47:29.438314Z",
     "shell.execute_reply.started": "2024-12-16T02:47:28.486831Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:309: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47f6bf70f5fa47ef8d8a3b1a052e5cc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2260 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26d8f1284e81477ca8dee2a5dc6e73ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/119 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "source": [
    "# Configure the SFTTrainer\n",
    "sft_config = SFTConfig(\n",
    "    output_dir=\"./sft_output\",\n",
    "    max_steps=1000,  # Adjust based on dataset size and desired training duration\n",
    "    per_device_train_batch_size=4,  # Set according to your GPU memory capacity\n",
    "    learning_rate=5e-5,  # Common starting point for fine-tuning\n",
    "    logging_steps=10,  # Frequency of logging training metrics\n",
    "    save_steps=500,  # Frequency of saving model checkpoints\n",
    "    evaluation_strategy=\"steps\",  # Evaluate the model at regular intervals\n",
    "    eval_steps=50,  # Frequency of evaluation\n",
    "    use_mps_device=(\n",
    "        True if device == \"mps\" else False\n",
    "    ),  # Use MPS for mixed precision training\n",
    "    hub_model_id=finetune_name,  # Set a unique name for your model\n",
    ")\n",
    "\n",
    "# Initialize the SFTTrainer\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=sft_config,\n",
    "    train_dataset=ds[\"train\"],\n",
    "    tokenizer=tokenizer,\n",
    "    eval_dataset=ds[\"test\"],\n",
    ")\n",
    "\n",
    "\n",
    "# TODO: ü¶Å üêï cƒÉn ch·ªânh c√°c tham s·ªë SFTTrainer v·ªõi b·ªô d·ªØ li·ªáu b·∫°n ƒë√£ ch·ªçn.\n",
    "# V√≠ d·ª•, n·∫øu b·∫°n ƒëang s·ª≠ d·ª•ng b·ªô `bigcode/the-stack-smol`, b·∫°n s·∫Ω c·∫ßn ch·ªçn c·ªôt `content`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hu·∫•n luy·ªán M√¥ h√¨nh\n",
    "\n",
    "V·ªõi trainer ƒë√£ ƒë∆∞·ª£c ƒëi·ªÅu ch·ªânh, ch√∫ng ta c√≥ th·ªÉ ti·∫øn h√†nh hu·∫•n luy·ªán m√¥ h√¨nh. Qu√° tr√¨nh hu·∫•n luy·ªán s·∫Ω bao g·ªìm\n",
    "- L·∫∑p qua b·ªô d·ªØ li·ªáu\n",
    "- T√≠nh to√°n loss\n",
    "- C·∫≠p nh·∫≠t c√°c tham s·ªë c·ªßa m√¥ h√¨nh ƒë·ªÉ gi·∫£m thi·ªÉu loss n√†y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T02:47:33.899581Z",
     "iopub.status.busy": "2024-12-16T02:47:33.899181Z",
     "iopub.status.idle": "2024-12-16T02:51:58.591033Z",
     "shell.execute_reply": "2024-12-16T02:51:58.590101Z",
     "shell.execute_reply.started": "2024-12-16T02:47:33.899539Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 04:22, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.756100</td>\n",
       "      <td>1.141541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.986200</td>\n",
       "      <td>1.127008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.058100</td>\n",
       "      <td>1.093515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.034800</td>\n",
       "      <td>1.076862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.032500</td>\n",
       "      <td>1.067737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.026700</td>\n",
       "      <td>1.059902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.997400</td>\n",
       "      <td>1.053492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.005100</td>\n",
       "      <td>1.050071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>1.020400</td>\n",
       "      <td>1.041810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.077500</td>\n",
       "      <td>1.032910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.989900</td>\n",
       "      <td>1.027398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.782200</td>\n",
       "      <td>1.035131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.784200</td>\n",
       "      <td>1.032957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.733800</td>\n",
       "      <td>1.034466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.828100</td>\n",
       "      <td>1.032331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.773200</td>\n",
       "      <td>1.029445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.757600</td>\n",
       "      <td>1.030332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.804800</td>\n",
       "      <td>1.027934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>1.027188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.783400</td>\n",
       "      <td>1.026968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Hu·∫•n luy·ªán m√¥ h√¨nh\n",
    "trainer.train()\n",
    "\n",
    "# L∆∞u m√¥ h√¨nh\n",
    "trainer.save_model(f\"./{finetune_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T02:52:03.745452Z",
     "iopub.status.busy": "2024-12-16T02:52:03.744511Z",
     "iopub.status.idle": "2024-12-16T02:52:25.243751Z",
     "shell.execute_reply": "2024-12-16T02:52:25.242986Z",
     "shell.execute_reply.started": "2024-12-16T02:52:03.745417Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c04fcce5e2341c5bef4cb1ff42f36db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training_args.bin:   0%|          | 0.00/5.56k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8a85cc7fa9546b59335a64560a2d8aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "events.out.tfevents.1734317197.a2f500f6528f.23.0:   0%|          | 0.00/7.91k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "339d79ea3a8047279bc5ebf81f55d495",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 4 LFS files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57d6083e2adb49a3a2f840aae5390abd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/538M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c300e3faa0f34f77bb6521c409cc2a70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "events.out.tfevents.1734317254.a2f500f6528f.23.1:   0%|          | 0.00/32.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/quyettv/SmolLM2-FT-everyday/commit/8c7b4eae32d7f3035b002403cb55c80395e7bc65', commit_message='End of training', commit_description='', oid='8c7b4eae32d7f3035b002403cb55c80395e7bc65', pr_url=None, repo_url=RepoUrl('https://huggingface.co/quyettv/SmolLM2-FT-everyday', endpoint='https://huggingface.co', repo_type='model', repo_id='quyettv/SmolLM2-FT-everyday'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ƒê∆∞a m√¥ h√¨nh l√™n Hugging Face Hub\n",
    "trainer.push_to_hub(tags=finetune_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='background-color: lightblue; padding: 10px; border-radius: 5px; margin-bottom: 20px; color:black'>\n",
    "    <h2 style='margin: 0;color:blue'>B√†i t·∫≠p th√™m: Sinh vƒÉn b·∫£n v·ªõi m√¥ h√¨nh v·ª´a ƒë∆∞·ª£c hu·∫•n luy·ªán</h2>\n",
    "    <p>üêï S·ª≠ d·ª•ng m√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán ƒë·ªÉ sinh ra ph·∫£n h·ªìi, gi·ªëng nh∆∞ v·ªõi v√≠ d·ª• ban ƒë·∫ßu.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T02:52:29.557546Z",
     "iopub.status.busy": "2024-12-16T02:52:29.556802Z",
     "iopub.status.idle": "2024-12-16T02:52:32.596923Z",
     "shell.execute_reply": "2024-12-16T02:52:32.596028Z",
     "shell.execute_reply.started": "2024-12-16T02:52:29.557509Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training:\n",
      "user\n",
      "Write a haiku about programming\n",
      "assistant\n",
      "Hello! How can I help you today? I'm a language model and I'm looking for some programming haikus to share with you. What's programming? It's a type of programming where you write instructions for a computer to follow, like telling it how to play a game or solve a problem. Have you heard of programming languages before? They're special sets of instructions that computers understand. Some popular ones include Python, Java, and JavaScript. What's programming language\n"
     ]
    }
   ],
   "source": [
    "# Ki·ªÉm tra m√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán tr√™n c√πng m·ªôt y√™u c·∫ßu\n",
    "\n",
    "# Ki·ªÉm tra m√¥ h√¨nh g·ªëc tr∆∞·ªõc khi hu·∫•n luy·ªán\n",
    "prompt = \"Write a haiku about programming\"\n",
    "\n",
    "# ƒê·ªãnh d·∫°ng chat\n",
    "messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "formatted_prompt = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "\n",
    "# Sinh ph·∫£n h·ªìi t·ª´ m√¥ h√¨nh\n",
    "inputs = tokenizer(formatted_prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "# TODO: s·ª≠ d·ª•ng m√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán ƒë·ªÉ sinh ph·∫£n h·ªìi, gi·ªëng nh∆∞ v·ªõi v√≠ d·ª•.\n",
    "outputs = model.generate(**inputs, max_new_tokens=100)\n",
    "print(\"After training:\")\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíê Ch√∫c m·ª´ng b·∫°n. B·∫°n ƒë√£ ho√†n th√†nh!\n",
    "\n",
    "B√†i t·∫≠p n√†y ƒë√£ cung c·∫•p h∆∞·ªõng d·∫´n t·ª´ng b∆∞·ªõc ƒë·ªÉ b·∫°n hu·∫•n luy·ªán ƒë∆∞·ª£c m√¥ h√¨nh `HuggingFaceTB/SmolLM2-135M` s·ª≠ d·ª•ng `SFTTrainer`. B·∫±ng c√°ch l√†m theo c√°c b∆∞·ªõc n√†y, b·∫°n c√≥ th·ªÉ ƒëi·ªÅu ch·ªânh m√¥ h√¨nh ƒë·ªÉ th·ª±c hi·ªán c√°c t√°c v·ª• c·ª• th·ªÉ hi·ªáu qu·∫£ h∆°n. N·∫øu b·∫°n mu·ªën ti·∫øp t·ª•c l√†m vi·ªác v·ªõi kh√≥a h·ªçc n√†y, ƒë√¢y l√† m·ªôt s·ªë b∆∞·ªõc b·∫°n c√≥ th·ªÉ th·ª≠:\n",
    "\n",
    "- Th·ª≠ notebook n√†y ·ªü m·ª©c ƒë·ªô kh√≥ h∆°n\n",
    "- Review PR c·ªßa h·ªçc vi√™n kh√°c\n",
    "- C·∫£i thi·ªán t√†i li·ªáu kh√≥a h·ªçc th√¥ng qua Issue ho·∫∑c PR."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
