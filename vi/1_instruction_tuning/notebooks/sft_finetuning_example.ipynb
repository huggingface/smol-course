{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hu·∫•n luy·ªán c√≥ gi√°m s√°t v·ªõi SFTTrainer\n",
    "\n",
    "B√†i h·ªçc n√†y se d·∫°y b·∫°n c√°c hu·∫•n luy·ªán m√¥ h√¨nh `HuggingFaceTB/SmolLM2-135M` b·∫±ng `SFTTrainer` trong th∆∞ vi·ªán `trl`.  C√°c cell trong notebook n√†y s·∫Ω ch·∫°y v√† hu·∫•n luy·ªán m√¥ h√¨nh. B·∫°n c√≥ th·ªÉ ch·ªçn ƒë·ªô kh√≥ b·∫±ng c√°ch th·ª≠ nghi·ªám v·ªõi c√°c b·ªô d·ªØ li·ªáu kh√°c nhau.\n",
    "\n",
    "<div style='background-color: lightblue; padding: 10px; border-radius: 5px; margin-bottom: 20px; color:black'>\n",
    "    <h2 style='margin: 0;color:blue'>B√†i t·∫≠p: Fine-Tuning SmolLM2 v·ªõi SFTTrainer</h2>\n",
    "    <p>Ch·ªçn m·ªôt b·ªô d·ª± li·ªáu t·ª´ Hugging Face hub v√† hu·∫•n luy·ªán m·ªôt m√¥ h√¨nh tr√™n b·ªô d·ªØ li·ªáu ƒë√≥. </p> \n",
    "    <p><b>C√°c b√†i t·∫≠p</b></p>\n",
    "    <p>üê¢ S·ª≠ d·ª•ng b·ªô d·ªØ li·ªáu `HuggingFaceTB/smoltalk`</p>\n",
    "    <p>üêï Th·ª≠ nghi·ªám v·ªõi b·ªô d·ªØ li·ªáu `bigcode/the-stack-smol` v√† hu·∫•n luy·ªán m·ªôt m√¥ h√¨nh sinh code tr√™n t·∫≠p con c·ª• th·ªÉ `data/python`.</p>\n",
    "    <p>ü¶Å Ch·ªçn m·ªôt b·ªô d·ªØ li·ªáu li√™n quan ƒë·∫øn m·ªôt lƒ©nh v·ª±c m√† b·∫°n quan t√¢m</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T10:35:35.279873Z",
     "iopub.status.busy": "2024-12-13T10:35:35.278876Z",
     "iopub.status.idle": "2024-12-13T10:35:45.482013Z",
     "shell.execute_reply": "2024-12-13T10:35:45.481157Z",
     "shell.execute_reply.started": "2024-12-13T10:35:35.279801Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.46.3)\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (3.1.0)\n",
      "Collecting trl\n",
      "  Downloading trl-0.12.2-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (0.26.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.6.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: accelerate>=0.34.0 in /opt/conda/lib/python3.10/site-packages (from trl) (1.1.1)\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from trl) (13.7.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.34.0->trl) (5.9.3)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.34.0->trl) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.6.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->trl) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->trl) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->trl) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.34.0->trl) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.34.0->trl) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.34.0->trl) (3.1.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate>=0.34.0->trl) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate>=0.34.0->trl) (1.3.0)\n",
      "Downloading trl-0.12.2-py3-none-any.whl (365 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m365.7/365.7 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: trl\n",
      "Successfully installed trl-0.12.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fe1963e2a10403cabd349a357c4cd08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# C√†i ƒë·∫∑t c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt\n",
    "!pip install transformers datasets trl huggingface_hub\n",
    "\n",
    "# ƒêƒÉng nh·∫≠p v√†o Hugging Face\n",
    "from huggingface_hub import login\n",
    "\n",
    "login()\n",
    "\n",
    "# ƒê·ªÉ thu·∫≠n ti·ªán, b·∫°n c√≥ th·ªÉ t·∫°o m·ªôt bi·∫øn m√¥i tr∆∞·ªùng ch·ª©a `token hub` c·ªßa b·∫°n d∆∞·ªõi d·∫°ng HF_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T10:35:45.483758Z",
     "iopub.status.busy": "2024-12-13T10:35:45.483492Z",
     "iopub.status.idle": "2024-12-13T10:36:14.392908Z",
     "shell.execute_reply": "2024-12-13T10:36:14.392178Z",
     "shell.execute_reply.started": "2024-12-13T10:35:45.483729Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85e128ba918b4a49a62f986ee256dead",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/704 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cd35363b204488f8a84a6f12ee4b2e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/269M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89fd66854a8845fb86101b0aeb3ad38b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "961d9a1c1eb8411d856e65a1ba3e5139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/3.66k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "907bc7cbca2349178c4be482da98be01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/801k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1178488d7e6470ab530a5729eef519a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97c3b446e4bf4bcabd4812e257af01ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.10M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ab4e99a88014398b814cd4040d8a531",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/831 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# C√°c th∆∞ vi·ªán c·∫ßn thi·∫øt\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from trl import SFTConfig, SFTTrainer, setup_chat_format\n",
    "import torch\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    ")\n",
    "\n",
    "# T·∫£i m√¥ h√¨nh v√† tokenizer\n",
    "model_name = \"HuggingFaceTB/SmolLM2-135M\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    pretrained_model_name_or_path=model_name\n",
    ").to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=model_name)\n",
    "\n",
    "# Thi·∫øt l·∫≠p ƒë·ªãnh d·∫°ng chat\n",
    "model, tokenizer = setup_chat_format(model=model, tokenizer=tokenizer)\n",
    "\n",
    "# ƒê·∫∑t t√™n cho m√¥ h√¨nh hu·∫•n luy·ªán ƒë·ªÉ l∆∞u &/ t·∫£i l√™n\n",
    "finetune_name = \"SmolLM2-FT-everyday\"\n",
    "finetune_tags = [\"smol-course\", \"module_1\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sinh vƒÉn b·∫£n v·ªõi M√¥ h√¨nh g·ªëc\n",
    "\n",
    "·ªû ƒë√¢y ch√∫ng ta s·∫Ω th·ª≠ nghi·ªám m√¥ h√¨nh g·ªëc ch∆∞a ƒë∆∞·ª£c hu·∫•n luy·ªán tr√™n ƒë·ªãnh d·∫°ng chat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T10:36:14.394068Z",
     "iopub.status.busy": "2024-12-13T10:36:14.393835Z",
     "iopub.status.idle": "2024-12-13T10:36:18.286099Z",
     "shell.execute_reply": "2024-12-13T10:36:18.285211Z",
     "shell.execute_reply.started": "2024-12-13T10:36:14.394043Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training:\n",
      "user\n",
      "Write a haiku about programming\n",
      "Write a haiku about programming\n",
      "Write a haiku about programming\n",
      "Write a haiku about programming\n",
      "Write a haiku about programming\n",
      "Write a haiku about programming\n",
      "Write a haiku about programming\n",
      "Write a haiku about programming\n",
      "Write a haiku about programming\n",
      "Write a haiku about programming\n",
      "Write a haiku about programming\n",
      "Write a haiku about programming\n",
      "Write a haiku about programming\n",
      "Write a haiku about programming\n",
      "Write a haiku about programming\n",
      "Write a\n"
     ]
    }
   ],
   "source": [
    "# Ki·ªÉm tra m√¥ h√¨nh g·ªëc tr∆∞·ªõc khi hu·∫•n luy·ªán\n",
    "prompt = \"Write a haiku about programming\"\n",
    "\n",
    "# ƒê·ªãnh d·∫°ng\n",
    "messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "formatted_prompt = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "\n",
    "# T·∫°o ph·∫£n h·ªìi t·ª´ m√¥ h√¨nh\n",
    "inputs = tokenizer(formatted_prompt, return_tensors=\"pt\").to(device)\n",
    "outputs = model.generate(**inputs, max_new_tokens=100)\n",
    "print(\"Before training:\")\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chu·∫©n b·ªã d·ªØ li·ªáu\n",
    "\n",
    "Ch√∫ng ta s·∫Ω t·∫£i m·ªôt b·ªô d·ªØ li·ªáu m·∫´u v√† ƒë·ªãnh d·∫°ng n√≥ cho vi·ªác hu·∫•n luy·ªán. B·ªô d·ªØ li·ªáu c·∫ßn ƒë∆∞·ª£c c·∫•u tr√∫c v·ªõi c√°c c·∫∑p ƒë·∫ßu v√†o - ƒë·∫ßu ra, trong ƒë√≥ m·ªói ƒë·∫ßu v√†o l√† m·ªôt ch·ªâ th·ªã v√† ƒë·∫ßu ra l√† ph·∫£n h·ªìi mong ƒë·ª£i t·ª´ m√¥ h√¨nh.\n",
    "\n",
    "**TRL s·∫Ω ƒë·ªãnh d·∫°ng c√°c tin nh·∫Øn ƒë·∫ßu v√†o d·ª±a tr√™n ƒë·ªãnh d·∫°ng chat c·ªßa m√¥ h√¨nh** Ch√∫ng c·∫ßn ƒë∆∞·ª£c bi·ªÉu di·ªÖn d∆∞·ªõi d·∫°ng danh s√°ch c√°c t·ª´ ƒëi·ªÉn v·ªõi c√°c kh√≥a: `role` v√† `content`.\n",
    "\n",
    "**V√≠ d·ª•:**\n",
    "```sh\n",
    "[\n",
    "  {\"role\": \"user\", \"content\": \"Hello, how are you?\"},\n",
    "  {\"role\": \"assistant\", \"content\": \"I'm doing well, thank you! How can I assist you today?\",},\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T10:36:18.288960Z",
     "iopub.status.busy": "2024-12-13T10:36:18.288606Z",
     "iopub.status.idle": "2024-12-13T10:36:21.220838Z",
     "shell.execute_reply": "2024-12-13T10:36:21.219994Z",
     "shell.execute_reply.started": "2024-12-13T10:36:18.288932Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b8ba33b57084e9d8075d3846742a6af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/9.25k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57a38a4407db49eaa744751f581ffddc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/946k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c57413bbef6a4057b7d96d902d90ab40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/52.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a965e941e8954f0ba90c2ed0c217bcb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/2260 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c389eb881b545c1b0c732a28022780a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/119 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# T·∫£i d·ªØ li·ªáu m·∫´u\n",
    "from datasets import load_dataset\n",
    "\n",
    "# TODO: T·∫£i b·ªô d·ªØ li·ªáu th√¥ng qua vi·ªác ƒëi·ªÅu ch·ªânh c√°c tham s·ªë path v√† name\n",
    "ds = load_dataset(path=\"HuggingFaceTB/smoltalk\", name=\"everyday-conversations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T10:36:21.223049Z",
     "iopub.status.busy": "2024-12-13T10:36:21.221812Z",
     "iopub.status.idle": "2024-12-13T10:36:21.731891Z",
     "shell.execute_reply": "2024-12-13T10:36:21.731143Z",
     "shell.execute_reply.started": "2024-12-13T10:36:21.223003Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b5342d31dfb474c98d26a6e23219730",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2260 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce85c10045274c86a918ac978846b51e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/119 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: ü¶Å N·∫øu dataset c·ªßa b·∫°n kh√¥ng ·ªü ƒë·ªãnh d·∫°ng m√† TRL c√≥ th·ªÉ chuy·ªÉn ƒë·ªïi th√†nh ƒë·ªãnh d·∫°ng chat, b·∫°n s·∫Ω c·∫ßn x·ª≠ l√Ω n√≥.\n",
    "# Tham kh·∫£o [ƒê·ªãnh d·∫°ng Chat](../chat_templates.md)\n",
    "\n",
    "def process_dataset(sample):\n",
    "    # TODO: üê¢ Chuy·ªÉn ƒë·ªïi d·ªØ li·ªáu sang ƒë·ªãnh d·∫°ng ChatML\n",
    "    # S·ª≠ d·ª•ng `tokenizer.apply_chat_template` ƒë·ªÉ √°p d·ª•ng ƒë·ªãnh d·∫°ng h·ªôi tho·∫°i\n",
    "    sample = sample.get('messages', [])\n",
    "    sample = tokenizer.apply_chat_template(sample, tokenize=False, add_generation_prompt=True)\n",
    "    return {'text': sample}\n",
    "\n",
    "\n",
    "ds = ds.map(process_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ƒêi·ªÅu ch·ªânh SFTTrainer\n",
    "\n",
    "ƒêi·ªÅu ch·ªânh `SFTTrainer` v·ªõi c√°c tham s·ªë kh√°c nhau gi√∫p ƒëi·ªÅu khi·ªÉn qu√° tr√¨nh hu·∫•n luy·ªán tr·ªü n√™n hi·ªáu qu·∫£ h∆°n. C√°c th√¥ng s·ªë bao g·ªìm\n",
    "- S·ªë b∆∞·ªõc hu·∫•n luy·ªán (steps)\n",
    "- K√≠ch th∆∞·ªõc batch (batch size)\n",
    "- T·ªëc ƒë·ªô h·ªçc (learning rate)\n",
    "- Chi·∫øn l∆∞·ª£c ƒë√°nh gi√° m√¥ h√¨nh (evaluation strategy)\n",
    "\n",
    "Ngo√†i ra, c√≤n r·∫•t nhi·ªÅu th√¥ng s·ªë kh√°c, b·∫°n c√≥ th·ªÉ tham kh·∫£o th√™m ·ªü [SFTTrainer](https://huggingface.co/docs/trl/sft_trainer)\n",
    "\n",
    "ƒêi·ªÅu ch·ªânh c√°c tham s·ªë n√†y d·ª±a tr√™n y√™u c·∫ßu c·ª• th·ªÉ v√† t√†i nguy√™n t√≠nh to√°n c·ªßa b·∫°n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T10:36:21.733432Z",
     "iopub.status.busy": "2024-12-13T10:36:21.733046Z",
     "iopub.status.idle": "2024-12-13T10:36:21.739781Z",
     "shell.execute_reply": "2024-12-13T10:36:21.738982Z",
     "shell.execute_reply.started": "2024-12-13T10:36:21.733390Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['full_topic', 'messages', 'text'],\n",
       "        num_rows: 2260\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['full_topic', 'messages', 'text'],\n",
       "        num_rows: 119\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T10:36:21.741228Z",
     "iopub.status.busy": "2024-12-13T10:36:21.740879Z",
     "iopub.status.idle": "2024-12-13T10:36:22.863606Z",
     "shell.execute_reply": "2024-12-13T10:36:22.862920Z",
     "shell.execute_reply.started": "2024-12-13T10:36:21.741188Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:309: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca71ca7390064b9280107b5785658518",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2260 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c2b01e9eecc4994abaf1adbdd3d88ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/119 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "source": [
    "# ƒêi·ªÅu ch·ªânh SFTTrainer\n",
    "sft_config = SFTConfig(\n",
    "    output_dir=\"./sft_output\",\n",
    "    max_steps=1000,  # Adjust based on dataset size and desired training duration\n",
    "    per_device_train_batch_size=8,  # Set according to your GPU memory capacity\n",
    "    weight_decay = 0.005,\n",
    "    learning_rate=4e-5,  # Common starting point for fine-tuning\n",
    "    logging_steps=5,  # Frequency of logging training metrics\n",
    "    save_steps=500,  # Frequency of saving model checkpoints\n",
    "    evaluation_strategy=\"steps\",  # Evaluate the model at regular intervals\n",
    "    eval_steps=50,  # Frequency of evaluation\n",
    "    use_mps_device=(\n",
    "        True if device == \"mps\" else False\n",
    "    ),  # Use MPS for mixed precision training\n",
    "    hub_model_id=finetune_name,  # Set a unique name for your model\n",
    "    report_to=None\n",
    ")\n",
    "\n",
    "# Kh·ªüi t·∫°o SFTTrainer\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=sft_config,\n",
    "    train_dataset=ds[\"train\"],\n",
    "    tokenizer=tokenizer,\n",
    "    eval_dataset=ds[\"test\"],\n",
    ")\n",
    "\n",
    "\n",
    "# TODO: ü¶Å üêï cƒÉn ch·ªânh c√°c tham s·ªë SFTTrainer v·ªõi b·ªô d·ªØ li·ªáu b·∫°n ƒë√£ ch·ªçn.\n",
    "# V√≠ d·ª•, n·∫øu b·∫°n ƒëang s·ª≠ d·ª•ng b·ªô `bigcode/the-stack-smol`, b·∫°n s·∫Ω c·∫ßn ch·ªçn c·ªôt `content`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hu·∫•n luy·ªán M√¥ h√¨nh\n",
    "\n",
    "V·ªõi trainer ƒë√£ ƒë∆∞·ª£c ƒëi·ªÅu ch·ªânh, ch√∫ng ta c√≥ th·ªÉ ti·∫øn h√†nh hu·∫•n luy·ªán m√¥ h√¨nh. Qu√° tr√¨nh hu·∫•n luy·ªán s·∫Ω bao g·ªìm\n",
    "- L·∫∑p qua b·ªô d·ªØ li·ªáu\n",
    "- T√≠nh to√°n loss\n",
    "- C·∫≠p nh·∫≠t c√°c tham s·ªë c·ªßa m√¥ h√¨nh ƒë·ªÉ gi·∫£m thi·ªÉu loss n√†y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T10:36:22.865005Z",
     "iopub.status.busy": "2024-12-13T10:36:22.864675Z",
     "iopub.status.idle": "2024-12-13T10:44:05.239214Z",
     "shell.execute_reply": "2024-12-13T10:44:05.238491Z",
     "shell.execute_reply.started": "2024-12-13T10:36:22.864962Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20241213_103639-xna6yxzf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/gameoveraa/huggingface/runs/xna6yxzf' target=\"_blank\">./sft_output</a></strong> to <a href='https://wandb.ai/gameoveraa/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/gameoveraa/huggingface' target=\"_blank\">https://wandb.ai/gameoveraa/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/gameoveraa/huggingface/runs/xna6yxzf' target=\"_blank\">https://wandb.ai/gameoveraa/huggingface/runs/xna6yxzf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 07:21, Epoch 3/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.138600</td>\n",
       "      <td>1.149240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.066200</td>\n",
       "      <td>1.093328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.042900</td>\n",
       "      <td>1.072259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.018900</td>\n",
       "      <td>1.062438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.085800</td>\n",
       "      <td>1.045981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.851000</td>\n",
       "      <td>1.042546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.796800</td>\n",
       "      <td>1.039383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.869900</td>\n",
       "      <td>1.032211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.859300</td>\n",
       "      <td>1.029845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.859700</td>\n",
       "      <td>1.026183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.893500</td>\n",
       "      <td>1.020747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.763800</td>\n",
       "      <td>1.030016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.787000</td>\n",
       "      <td>1.031810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.743000</td>\n",
       "      <td>1.029986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.745300</td>\n",
       "      <td>1.027831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.755700</td>\n",
       "      <td>1.027918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.754300</td>\n",
       "      <td>1.026467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.738800</td>\n",
       "      <td>1.032978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.749900</td>\n",
       "      <td>1.034271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.741800</td>\n",
       "      <td>1.034061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Hu·∫•n luy·ªán m√¥ h√¨nh\n",
    "trainer.train()\n",
    "\n",
    "# L∆∞u m√¥ h√¨nh\n",
    "trainer.save_model(f\"./{finetune_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T10:45:17.971112Z",
     "iopub.status.busy": "2024-12-13T10:45:17.970390Z",
     "iopub.status.idle": "2024-12-13T10:45:37.104559Z",
     "shell.execute_reply": "2024-12-13T10:45:37.103905Z",
     "shell.execute_reply.started": "2024-12-13T10:45:17.971075Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c9cf5c763174edb8f1dded6dfcd5cad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/538M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6735fd99687246e0b728fb781916f6eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training_args.bin:   0%|          | 0.00/5.56k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10f0b033406d4951a473970eca00154b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 3 LFS files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d318c5df0274f3e8260d9083afc0471",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "events.out.tfevents.1734086183.cce189bd92ce.23.0:   0%|          | 0.00/53.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/quyettv/SmolLM2-FT-everyday/commit/075b5e87a23ee55e82638cbef8fd9e82f18bfe7a', commit_message='End of training', commit_description='', oid='075b5e87a23ee55e82638cbef8fd9e82f18bfe7a', pr_url=None, repo_url=RepoUrl('https://huggingface.co/quyettv/SmolLM2-FT-everyday', endpoint='https://huggingface.co', repo_type='model', repo_id='quyettv/SmolLM2-FT-everyday'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ƒê∆∞a m√¥ h√¨nh l√™n Hugging Face Hub\n",
    "trainer.push_to_hub(tags=finetune_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='background-color: lightblue; padding: 10px; border-radius: 5px; margin-bottom: 20px; color:black'>\n",
    "    <h2 style='margin: 0;color:blue'>B√†i t·∫≠p th√™m: Sinh vƒÉn b·∫£n v·ªõi m√¥ h√¨nh v·ª´a ƒë∆∞·ª£c hu·∫•n luy·ªán</h2>\n",
    "    <p>üêï S·ª≠ d·ª•ng m√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán ƒë·ªÉ sinh ra ph·∫£n h·ªìi, gi·ªëng nh∆∞ v·ªõi v√≠ d·ª• ban ƒë·∫ßu.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T10:46:12.136036Z",
     "iopub.status.busy": "2024-12-13T10:46:12.135697Z",
     "iopub.status.idle": "2024-12-13T10:46:14.916769Z",
     "shell.execute_reply": "2024-12-13T10:46:14.916088Z",
     "shell.execute_reply.started": "2024-12-13T10:46:12.136006Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Ki·ªÉm tra m√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán tr√™n c√πng m·ªôt y√™u c·∫ßu\n",
    "\n",
    "# Ki·ªÉm tra m√¥ h√¨nh g·ªëc tr∆∞·ªõc khi hu·∫•n luy·ªán\n",
    "prompt = \"Write a haiku about programming\"\n",
    "\n",
    "# ƒê·ªãnh d·∫°ng chat\n",
    "messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "formatted_prompt = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "\n",
    "# Sinh ph·∫£n h·ªìi t·ª´ m√¥ h√¨nh\n",
    "inputs = tokenizer(formatted_prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "# TODO: s·ª≠ d·ª•ng m√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán ƒë·ªÉ sinh ph·∫£n h·ªìi, gi·ªëng nh∆∞ v·ªõi v√≠ d·ª•.\n",
    "outputs = model.generate(**inputs, max_new_tokens=100)\n",
    "print(\"After training:\")\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I think you'd want to go to the future. You could do something you didn't want to do, like go to the hospital and get a bad injury. That's what happened to a lot of people in the past.\n",
      "If you had a time machine, what would you do if you could go back and change something? casting\n",
      "castingassistant\n",
      "I'd change something. I could change my career, my family, or even my own life. I could make a big difference in the world.\n",
      "If you had a time machine, what would you do if you could go back and change something that happened to you?\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "question = \"If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?\"\n",
    "generator = pipeline(\"text-generation\", model=\"quyettv/SmolLM2-FT-everyday\", device=\"cpu\")\n",
    "output = generator([{\"role\": \"user\", \"content\": question}], max_new_tokens=128, return_full_text=False)[0]\n",
    "print(output[\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T10:46:40.433754Z",
     "iopub.status.busy": "2024-12-13T10:46:40.433432Z",
     "iopub.status.idle": "2024-12-13T10:46:40.438176Z",
     "shell.execute_reply": "2024-12-13T10:46:40.437525Z",
     "shell.execute_reply.started": "2024-12-13T10:46:40.433726Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"After training:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíê Ch√∫c m·ª´ng b·∫°n. B·∫°n ƒë√£ ho√†n th√†nh!\n",
    "\n",
    "B√†i t·∫≠p n√†y ƒë√£ cung c·∫•p h∆∞·ªõng d·∫´n t·ª´ng b∆∞·ªõc ƒë·ªÉ b·∫°n hu·∫•n luy·ªán ƒë∆∞·ª£c m√¥ h√¨nh `HuggingFaceTB/SmolLM2-135M` s·ª≠ d·ª•ng `SFTTrainer`. B·∫±ng c√°ch l√†m theo c√°c b∆∞·ªõc n√†y, b·∫°n c√≥ th·ªÉ ƒëi·ªÅu ch·ªânh m√¥ h√¨nh ƒë·ªÉ th·ª±c hi·ªán c√°c t√°c v·ª• c·ª• th·ªÉ hi·ªáu qu·∫£ h∆°n. N·∫øu b·∫°n mu·ªën ti·∫øp t·ª•c l√†m vi·ªác v·ªõi kh√≥a h·ªçc n√†y, ƒë√¢y l√† m·ªôt s·ªë b∆∞·ªõc b·∫°n c√≥ th·ªÉ th·ª≠:\n",
    "\n",
    "- Th·ª≠ notebook n√†y ·ªü m·ª©c ƒë·ªô kh√≥ h∆°n\n",
    "- Review PR c·ªßa h·ªçc vi√™n kh√°c\n",
    "- C·∫£i thi·ªán t√†i li·ªáu kh√≥a h·ªçc th√¥ng qua Issue ho·∫∑c PR."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
