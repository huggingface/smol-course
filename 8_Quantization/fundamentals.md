# Quantization Fundamentals

## What is Quantization?
Quantization is a technique used to reduce memory and computational costs by representing model weights and activations with lower-precision data types, such as 8-bit integers (int8). By doing so, it allows larger models to fit into memory and speeds up inference, making the model more efficient without significantly sacrificing performance.

## Quantization Techniques
We should focus on GPTQ? 

## Quantization for Inference


## Exercise Notebooks

## References
https://huggingface.co/docs/transformers/main_classes/quantization
https://huggingface.co/docs/transformers/v4.48.0/quantization/overview
https://huggingface.co/docs/optimum/en/concept_guides/quantization
https://huggingface.co/blog/introduction-to-ggml
https://huggingface.co/docs/hub/gguf
https://huggingface.co/docs/transformers/gguf
