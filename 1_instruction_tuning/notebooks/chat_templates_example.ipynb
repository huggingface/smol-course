{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZAvFVIAtFlq"
      },
      "source": [
        "# Exploring Chat Templates with SmolLM2\n",
        "\n",
        "This notebook demonstrates how to use chat templates with the `SmolLM2` model. Chat templates help structure interactions between users and AI models, ensuring consistent and contextually appropriate responses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-lZu8JvtwUN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "ff67d778f95e4d55aec610a1d55ae289",
            "df2142bde0ee4740b37984cbf7fab591",
            "88b1939adf5b4390a2ecbab638d0973e",
            "46265f431fc847efa916b6304d443e94",
            "4e07228eec7c4bbd9e3761ef57842e96",
            "0b893b0b5c504e1f9b3d2c668af7c526",
            "76f8f19dd17f487cbdcc1d58ee870441",
            "267e98a306b948b1a7978019f4fe158a",
            "bd058e3553ac4b9691db6845f531a6bd",
            "03f110d892d644169dc77667f0275904",
            "e8f7ba8a2d544b9cb1a48b05bcec4887",
            "e24a9b18ba12493e8d9da5401b3c72c1",
            "f85a6d361cc44cb18c0fc0a6bf5b4f78",
            "160a7d65b8a64d8cafd0ac9ecb87506e",
            "94cef48d87a74d9294fd51c9d75757da",
            "a6621265814d4db68b18d8aa05998de0",
            "b44bfeb6ecf04f609422b49769dd5043"
          ]
        },
        "outputId": "b0116d9d-cbcb-4a29-d420-8c32f7515e3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.3)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting trl\n",
            "  Downloading trl-0.12.2-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.26.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.10)\n",
            "Requirement already satisfied: accelerate>=0.34.0 in /usr/local/lib/python3.10/dist-packages (from trl) (1.1.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from trl) (13.9.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.0->trl) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.0->trl) (2.5.1+cu121)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->trl) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.34.0->trl) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.34.0->trl) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.34.0->trl) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate>=0.34.0->trl) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate>=0.34.0->trl) (3.0.2)\n",
            "Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trl-0.12.2-py3-none-any.whl (365 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.7/365.7 kB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets, trl\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.2.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 trl-0.12.2 xxhash-3.5.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ff67d778f95e4d55aec610a1d55ae289"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Install the requirements in Google Colab\n",
        "!pip install transformers datasets trl huggingface_hub\n",
        "\n",
        "# Authenticate to Hugging Face\n",
        "from huggingface_hub import login\n",
        "\n",
        "login()\n",
        "\n",
        "# for convenience you can create an environment variable containing your hub token as HF_TOKEN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tnHzBR7vtFlr"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from trl import setup_chat_format\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTVOqbuetFlr"
      },
      "source": [
        "## SmolLM2 Chat Template\n",
        "\n",
        "Let's explore how to use a chat template with the `SmolLM2` model. We'll define a simple conversation and apply the chat template."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nrxh0oX6tFls",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273,
          "referenced_widgets": [
            "e66e26f6ac1b4d828d17de3bb582099b",
            "c18bc9a86a9d4e5ca1e95f74b8afb3a2",
            "0d2d937f3af64fe5bddccc67cd41411e",
            "2995ef0454bd4144b709188237f9eac7",
            "3b5e810983584b6dab3a758fbada15f4",
            "331530fe6ba14f4bafe0d35a7fe68f19",
            "b3af4f725429448ea8afe257585a6a7b",
            "b6d28f9055274791969ab76e898334ed",
            "7f4acde3faae4734bb5d13bfcdc06ad7",
            "cbf4d496bed24b39936f9e175f7d10aa",
            "8c0daf1e83d547cb886738bbc76198b8",
            "3a161385f80c4751b291b49a448f232e",
            "e3fe7e5b39b94b6aa0d235a95b61c0a5",
            "e2e3c22e6bb3493481f08dad0ceab447",
            "6e2546cbca5148669cc2904465a9918b",
            "7f02ef248f0c4b22a6a6bf9bc6c37c51",
            "f94f593aa5e345caac56511de5adb4b0",
            "8059b942a84e4745aa412d65028e8b26",
            "5eb46bcbdf4c446594b37c89239e5c6f",
            "5e7baf6b8f3d449da2433c0ec01b93f7",
            "3ddd405f29c24916972986caf92142d2",
            "758be71e0095464bb20c9907896cac57",
            "7592784d85434165b8714ed4cec4c3a2",
            "c5e2c26c525941f290b2685e7fc3cfe8",
            "a4943d9bcf7946f7ac3395579a30c46d",
            "cf12c3728dde4fce9cb8eebca3ce531f",
            "cfefd1fe014143548931690a96555099",
            "1e9e19fbb7f34b0e8472cc8f0cf98271",
            "17882a7dcb8c4699bb2090575216f074",
            "be4dd4a754bb470eb9a182b5ee021326",
            "6eec9e04066e451692d7b21cf6295f76",
            "23c94071e51e41edb0161316e1b90311",
            "328bc436cc084564818b6cc6fb068e71",
            "31eccb89218748619ed83477f4d3e1b9",
            "3ce0b181086243d4a65d15fbc8a6d616",
            "ad9f8cbc28f640598e93a2faf6c1f1f1",
            "9c232fe12d894bc9bfea6d156dec213c",
            "4e9ca5049913403f91b28045505154ef",
            "074d86d2f2414e5694f21eccd92ba8a7",
            "b94482371c8c41f2b3ed568e9e6e608e",
            "9bc40056185c4ae58f5ed1c88e68e5e0",
            "39c18c43db88498d9060162224718441",
            "225f09bd6e1b4c20850b27d1ddc69981",
            "dadd88f8e8ee40f686ebdd72b1abc2f2",
            "902f60122c1b411c94c25aa2c43c97ac",
            "e7a3b378ddd44330b202a0018506b853",
            "769f345cd4274ca9982890aa98436397",
            "837eb22f18994403a657ba4fa6cae5a0",
            "4ff1c8d5ba704c7a9d771c97faec057c",
            "5cb0b0b8cf2e4e058bcd50737465d3f8",
            "6893b5bccc37438088c7eecb1b89d9fb",
            "692d209c269d4bd1921a8ca3632c1bab",
            "3a7d98b023d6497f8e25db5de96f4941",
            "529407d9f0eb4bc9b968e6a2614b79f7",
            "45458d30dacc4f2fbd1c21ab0c8c02bd",
            "90fccf0b51e04e22b0181e9efd794911",
            "1ec3bbc8f0f74d95aa07bd7d6e19085b",
            "96f272f4fc184c96b8c73aa9f5967126",
            "4760a458fe0746159b36321ee92def4a",
            "f1d2ed48c9284cf7a5b8848b10b22b83",
            "b27189d6e7484b659047fccaf449ed51",
            "f9bc65071bb848849b089791bbe0e4df",
            "b55ce6223e034c47817014aefd019940",
            "5f5d8011b2244040a2a8be0b1e08a32c",
            "564b1c47b9c140f581d64f8b6af44bef",
            "a2c095c6d93c49e1a6804b64fab7a2d0",
            "d0819b5984424cab8b3521344793b9e3",
            "364bbbfc9fa544bebadc0fb46aecfaf0",
            "a43a50db7622493f9ea2093000da1d45",
            "86bf3d1956e646bf9952fa514b1d6515",
            "245eaf75c29b48768018a1d6ddc06f25",
            "134f8b576be04c2499f42f9b5c3332a0",
            "15a0defd54b44e1b9bd6d884fb7f0fbb",
            "2ea7878fbff54fdf9e5b5013be618487",
            "13ce9d010ada4b809652db0cc1478da0",
            "ff08989a373046e8ae821dee0a6daf08",
            "6f06865ee48844679761cf819b7ca0c1",
            "e82e42e71f2942e79101244c0a921c2a",
            "b7ea49c940f44ac894ef9a16baa157ab",
            "0b57a93650db4830bfca1d1c0681f527",
            "285dc0679ea6434bbfdb5d80fe4326e4",
            "fb22866806194ae4926740e4605189a8",
            "9f565f41a9bc4c3e851b0940f3f2c941",
            "7864072f3eb8443ca91888a2c1baf0eb",
            "ee2e89645e38417bbfefa890e96e888c",
            "d2ae7f6f190c4aee95e635461a3bad9d",
            "433048b9a5e64735ad6453056d4b1c0f",
            "7ba1f6576a704151aa5c00b91498de77"
          ]
        },
        "outputId": "ebf97b94-e7f7-4078-e412-61c719683b32"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/704 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e66e26f6ac1b4d828d17de3bb582099b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/269M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3a161385f80c4751b291b49a448f232e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7592784d85434165b8714ed4cec4c3a2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/3.66k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "31eccb89218748619ed83477f4d3e1b9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/801k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "902f60122c1b411c94c25aa2c43c97ac"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "90fccf0b51e04e22b0181e9efd794911"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/2.10M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d0819b5984424cab8b3521344793b9e3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/831 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e82e42e71f2942e79101244c0a921c2a"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Dynamically set the device\n",
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
        ")\n",
        "\n",
        "model_name = \"HuggingFaceTB/SmolLM2-135M\"\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    pretrained_model_name_or_path=model_name\n",
        ").to(device)\n",
        "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=model_name)\n",
        "model, tokenizer = setup_chat_format(model=model, tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zkJwILrbtFls"
      },
      "outputs": [],
      "source": [
        "# Define messages for SmolLM2\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"Hello, how are you?\"},\n",
        "    {\n",
        "        \"role\": \"assistant\",\n",
        "        \"content\": \"I'm doing well, thank you! How can I assist you today?\",\n",
        "    },\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ve4dgtjstFls"
      },
      "source": [
        "# Apply chat template without tokenization\n",
        "\n",
        "The tokenizer represents the conversation as a string with special tokens to describe the role of the user and the assistant.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbAg-5x-tFls",
        "outputId": "77da4432-7784-4327-982a-02a238d6f169"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conversation with template: <|im_start|>user\n",
            "Hello, how are you?<|im_end|>\n",
            "<|im_start|>assistant\n",
            "I'm doing well, thank you! How can I assist you today?<|im_end|>\n",
            "\n"
          ]
        }
      ],
      "source": [
        "input_text = tokenizer.apply_chat_template(messages, tokenize=False)\n",
        "\n",
        "print(\"Conversation with template:\", input_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfvdglOqtFls"
      },
      "source": [
        "# Decode the conversation\n",
        "\n",
        "Note that the conversation is represented as above but with a further assistant message.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXUVdPeytFls",
        "outputId": "d7ff0032-0d84-432c-a87c-bc96235d0006"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conversation decoded: <|im_start|>user\n",
            "Hello, how are you?<|im_end|>\n",
            "<|im_start|>assistant\n",
            "I'm doing well, thank you! How can I assist you today?<|im_end|>\n",
            "<|im_start|>assistant\n",
            "\n"
          ]
        }
      ],
      "source": [
        "input_text = tokenizer.apply_chat_template(\n",
        "    messages, tokenize=True, add_generation_prompt=True\n",
        ")\n",
        "\n",
        "print(\"Conversation decoded:\", tokenizer.decode(token_ids=input_text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcZQpspEtFlt"
      },
      "source": [
        "# Tokenize the conversation\n",
        "\n",
        "Of course, the tokenizer also tokenizes the conversation and special token as ids that relate to the model's vocabulary.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jc2PLxAMtFlt",
        "outputId": "67880500-7cb6-47b0-b385-31e0dbe7881c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conversation tokenized: [1, 4093, 198, 19556, 28, 638, 359, 346, 47, 2, 198, 1, 520, 9531, 198, 57, 5248, 2567, 876, 28, 9984, 346, 17, 1073, 416, 339, 4237, 346, 1834, 47, 2, 198, 1, 520, 9531, 198]\n"
          ]
        }
      ],
      "source": [
        "input_text = tokenizer.apply_chat_template(messages, add_generation_prompt=True)\n",
        "\n",
        "print(\"Conversation tokenized:\", input_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3eNp9a0tFlt"
      },
      "source": [
        "<div style='background-color: lightblue; padding: 10px; border-radius: 5px; margin-bottom: 20px; color:black'>\n",
        "    <h2 style='margin: 0;color:blue'>Exercise: Process a dataset for SFT</h2>\n",
        "    <p>Take a dataset from the Hugging Face hub and process it for SFT. </p>\n",
        "    <p><b>Difficulty Levels</b></p>\n",
        "    <p>🐢 Convert the `HuggingFaceTB/smoltalk` dataset into chatml format.</p>\n",
        "    <p>🐕 Convert the `openai/gsm8k` dataset into chatml format.</p>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "qbkXV2_ItFlt",
        "outputId": "06deadc3-2c63-4660-d2bd-05096ef07c9f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<iframe\n",
              "  src=\"https://huggingface.co/datasets/HuggingFaceTB/smoltalk/embed/viewer/all/train?row=0\"\n",
              "  frameborder=\"0\"\n",
              "  width=\"100%\"\n",
              "  height=\"360px\"\n",
              "></iframe>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.core.display import display, HTML\n",
        "\n",
        "display(\n",
        "    HTML(\n",
        "        \"\"\"<iframe\n",
        "  src=\"https://huggingface.co/datasets/HuggingFaceTB/smoltalk/embed/viewer/all/train?row=0\"\n",
        "  frameborder=\"0\"\n",
        "  width=\"100%\"\n",
        "  height=\"360px\"\n",
        "></iframe>\n",
        "\"\"\"\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4p3atw4_tFlu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241,
          "referenced_widgets": [
            "25377b6f3722459c918ddb93dd5bae66",
            "eee6d56ef8f54c259e2c0eb3969a4ced",
            "daa6a52dff3e4cc89f007f91a0ba03ad",
            "a1aa51c041034a0288fdd3774cfd97c3",
            "044443f745dc410594534818f40dd1fd",
            "38e66fb4440d43eaae20f25bf963d480",
            "2ec6171339fb4482a6963e5b2222d921",
            "e79c8ec918cd4eeea3a7669092352d11",
            "373a567c8f924922bdbfa22236604c91",
            "b2320c579f114231ac05eca9cc7689ab",
            "727e73385e1242aa981f6fee357eb056",
            "e3d49f7a9f1e4142bf578660ea1b4eab",
            "ee593b616bf243c9bf225f3d30bc58be",
            "2951395a9a8e478ea44538b6000cad57",
            "720f2c7f3c5546c5b0fe29447199b0ae",
            "657a39b126e740de9d84b0625404d2f8",
            "e0c5348095a349ef99ba3d2a47f51f8d",
            "82331c64dbae4034b87a221498a059ba",
            "6b4e408e6afb4cc3823c6b2505ca7973",
            "8006dc08a63641768831586dbc54f083",
            "2f10577ff3f2480fb5340f56b94c358f",
            "e7553f0192024508a0599e1197c923d3",
            "f5cc9d264173438ba4c3ce64854db023",
            "376e55b6579a4532ba904cbc54c92e85",
            "91fba656b85a4954b08506c1c37ca58b",
            "7d87579563024d9e87e722be3d3b645b",
            "fdcebe81d5374555b2fad9e385b8ffc0",
            "ee7dbb06f8c14a7db666d6e25ce32c6c",
            "9dbcd5b5e37a448e99ec3eb40b857248",
            "e633514f52d045f69158a6dcb32df0fc",
            "73c2861645bd43b2bc0c681fdc468e2d",
            "8af8d1d15bdc4620b9f935c3e4767274",
            "eee3cc3b0346475c866748ce795c1292",
            "6f3f1be837054470a04a7f384044639f",
            "50f6a517875845c79ebe9ca8d2ade2de",
            "a2da91207d914456b8e16a69cb408c0f",
            "eb93e5cb85b24155a9e39b97f3f16f99",
            "ede717e463cf45b381c7f4ddca6890ad",
            "deeb2780ed7a4f78a2a6d2158c17c9c4",
            "70999b6fd7694d94a740337ee3740b50",
            "912aecbbcde7400ea5d5540f47fdd0f0",
            "097f25acf598493ca70ab0acc3fd5a89",
            "d6c9fd0f5fe840eca241b1fd3b98942d",
            "36d57ceea6a747718cb0d6eb9a4cb414",
            "d5e08d9b678341d68e32d8fa1a6842ff",
            "d9ac9e7c30394274b15194b8b1caf77d",
            "c1dfc0f8b3d0438fb32965b9c5c00883",
            "56433180d8ad4af89abae6751976b0cb",
            "1b25004d8e4140889d5bcd34a646936a",
            "809b45a0f3ae4c24a8e00058c06b7d77",
            "806a2e71c7534377aba54dc26221707d",
            "eb5bbf2ecee3498f9476780aa01b7101",
            "b24ad674bf134ec6a20e3587590eb1fa",
            "dbd9768888f24e9f9071ad10dda5b82b",
            "b2c66d963c7447a88419e98ff5414c8e",
            "0062db5a8ccf42f9bae0930c4a00c3fd",
            "fdd106a1a7c44dfe966cc19796360765",
            "49b010ffb8c94556bb79c8bed79a3988",
            "017f883691bc4825966b4cf579b961d2",
            "b0203d1db0c940f1b900e3dd71f4bd92",
            "90e0be829f014095b69d979099dbde31",
            "04d9a1642ccd4337982a5956e29a3c7b",
            "f9fb78a714d64ed7ae94e0be5393f419",
            "bce41162e9584e40bb139aaa6e1ee0f7",
            "2cfa29280f224a998f986d43d9e629d6",
            "77cc556ccbfb4e57bcd9e7cc4cea3565",
            "4cf0c422a7a4456d8b0f860d07eea2df",
            "17ccbd0867a14729af671ef7c7adc837",
            "be49c91d268644858fc89d01ca2295eb",
            "865cd3845b5d49998beb15acfaa464e5",
            "84fcd9032be2496da8111c562812a2a0",
            "9b46acda2a3e4d6ebbd9b37f25380b4e",
            "4eb631e693bc4076960118174e51400d",
            "82ce7b203b084438814f2bafbd860443",
            "19dd5802ed954bf69424bd522fdfa494",
            "f989e98f5a3f4860bf2eb58c2694af58",
            "39f44cd1d1cc4ea6a16960f4f4995946"
          ]
        },
        "outputId": "4153024d-936a-4407-becf-9fdc29603e88"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/9.25k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "25377b6f3722459c918ddb93dd5bae66"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "train-00000-of-00001.parquet:   0%|          | 0.00/946k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e3d49f7a9f1e4142bf578660ea1b4eab"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "test-00000-of-00001.parquet:   0%|          | 0.00/52.6k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f5cc9d264173438ba4c3ce64854db023"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/2260 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6f3f1be837054470a04a7f384044639f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/119 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d5e08d9b678341d68e32d8fa1a6842ff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2260 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0062db5a8ccf42f9bae0930c4a00c3fd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/119 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4cf0c422a7a4456d8b0f860d07eea2df"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "ds = load_dataset(\"HuggingFaceTB/smoltalk\", \"everyday-conversations\")\n",
        "\n",
        "\n",
        "def process_dataset(sample):\n",
        "    # this is already in the chatml format\n",
        "    return sample\n",
        "\n",
        "\n",
        "ds = ds.map(process_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLHlw23n5jTT",
        "outputId": "964b61b3-813e-4a13-82f6-92019e9da798"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['full_topic', 'messages'],\n",
            "        num_rows: 2260\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['full_topic', 'messages'],\n",
            "        num_rows: 119\n",
            "    })\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds[\"train\"][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0s_VUn1i5nc-",
        "outputId": "f5770170-6068-4d88-cdc1-fcc3fb2c79d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'full_topic': 'Travel/Vacation destinations/Beach resorts',\n",
              " 'messages': [{'content': 'Hi there', 'role': 'user'},\n",
              "  {'content': 'Hello! How can I help you today?', 'role': 'assistant'},\n",
              "  {'content': \"I'm looking for a beach resort for my next vacation. Can you recommend some popular ones?\",\n",
              "   'role': 'user'},\n",
              "  {'content': \"Some popular beach resorts include Maui in Hawaii, the Maldives, and the Bahamas. They're known for their beautiful beaches and crystal-clear waters.\",\n",
              "   'role': 'assistant'},\n",
              "  {'content': 'That sounds great. Are there any resorts in the Caribbean that are good for families?',\n",
              "   'role': 'user'},\n",
              "  {'content': 'Yes, the Turks and Caicos Islands and Barbados are excellent choices for family-friendly resorts in the Caribbean. They offer a range of activities and amenities suitable for all ages.',\n",
              "   'role': 'assistant'},\n",
              "  {'content': \"Okay, I'll look into those. Thanks for the recommendations!\",\n",
              "   'role': 'user'},\n",
              "  {'content': \"You're welcome. I hope you find the perfect resort for your vacation.\",\n",
              "   'role': 'assistant'}]}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "81fQeazltFlu",
        "outputId": "36cf7148-9881-4f13-d0ce-76c82c4ab219"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<iframe\n",
              "  src=\"https://huggingface.co/datasets/openai/gsm8k/embed/viewer/main/train\"\n",
              "  frameborder=\"0\"\n",
              "  width=\"100%\"\n",
              "  height=\"360px\"\n",
              "></iframe>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(\n",
        "    HTML(\n",
        "        \"\"\"<iframe\n",
        "  src=\"https://huggingface.co/datasets/openai/gsm8k/embed/viewer/main/train\"\n",
        "  frameborder=\"0\"\n",
        "  width=\"100%\"\n",
        "  height=\"360px\"\n",
        "></iframe>\n",
        "\"\"\"\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "bWUSv7NMtFlu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241,
          "referenced_widgets": [
            "6bd57b15f4e047589ebb799e57878973",
            "2bf6cd1cfc14481fb6500e68d4253492",
            "4d0719b9401f4394891908a99019f3ca",
            "07d3009f84704e938169412edaf5017c",
            "db1f9ce1be584646b8ac9dc492019b43",
            "be77fa928ae04c21a8451a0bcc1b9145",
            "e76f3eff3eed41b798b4db00e5bb013c",
            "ab7bdff154af49c4be5b7868825ec0c9",
            "6814492af0394d9588eafb05ccbc910f",
            "c9b1971cbe0f4e3d9dc386d8777faa0f",
            "db46151f149b4e929a9a97b0f0b3273e",
            "fe25cd0ed6524223b74847ef5543c708",
            "a6078a7ec7b0470c83ba028957916a79",
            "c54af14c80e04590bf9c93e886e04aed",
            "5ad3ecd7181d4cfb930c79ffdb596063",
            "fe926a755b534128960357b1502c68c6",
            "aea24bddafa94c4fbeb77528ebd0a1c6",
            "bac2538e8e854322b8dd828abd15b46f",
            "568f84d58af04a1f923616b7109d8b99",
            "421b6fa4e1bd452da863d0455d03ed82",
            "c4c66a3e50c146e0a266c3c88194969c",
            "02d0e530604c44ec9e2eb4e138544b31",
            "d3968da19af44c549c654eef4f8723ac",
            "8a381319aaa0453b8b05b054e5d5a1c2",
            "c052d7570c8145ec8548225c239d385a",
            "d80c52d2286e4c2a83715babffc2dc59",
            "f9b3d31b70a9447186f6470a71ee95f5",
            "cdedf4a8cca14e42b0b7e5720c626d8f",
            "ee7c7cf33d204b3b9938c63c76917563",
            "dcbd1459735140839bd356bd66f9efbc",
            "ff39a49459b847448439073ed3b74ecc",
            "0362e01efd4d494086580b325344b8fd",
            "1dcd0df81ce646acaa06998b49cc01a0",
            "ba77a2d1aa4e46bc8324bcc5c6703a84",
            "7a0be20ff98d4057accc3d52b192589f",
            "0fbe3c0e9d8b43ba9594dfa755acabca",
            "2ee72d4d623647e0b441637a1dbd0c99",
            "4bdc2e0989c541f39ad0b091bed638c4",
            "231e1767f4de4a8c91e03d5201220673",
            "9f6252b5daec4820ab7a635516597e2e",
            "a2b7906ab33346cf98c19909ab462d3e",
            "22ceabd9d712448e8eb19ba31a41651d",
            "960df8b2db3e404d8c0f324e5b0d4fd5",
            "7043f813196d44cba2b36aa1e757f140",
            "16630f7161ce41e2b5f03be15e4a8be9",
            "f442df5db8ca4600b1f07dd332db57d4",
            "6e29ecb26173464281c43741440c15d0",
            "10c7d3545d5348a7bafeca945c8b6754",
            "3e9a46868b68418c8c0b1f246760bf32",
            "750d01b4ca284711b14a25c837995b80",
            "994f6ea5a43b413b9ef368eddc5ca8d2",
            "909c9f8b3c0d4c74b9b1f1b6d757d3d0",
            "c166da2f7d8b4c38bb12ff8dcf60de1c",
            "da29e3424b1d4340ab4b484b38de45dd",
            "0eb69829a46f48e1a34aeae27f603ea4",
            "7fdb99e1c4e34991a2de9f7bb994cd9b",
            "d17274b5b7854378a2c590a0d286e96a",
            "dd61026c0e334e46b686c1a7fe02fea9",
            "88bbda72743c47c38fe8b00821079535",
            "8fd2e25ee8344a96a0fab5b0af1c282e",
            "8a837f59190240afa3ea70e98208c59c",
            "1addfc3057b7496086660e59e944b576",
            "b91eb7bc648a466e9e437d894019b93f",
            "85b6392676a74f3db46aadb8c2555bf1",
            "e9c0a5b6700d4729b19f7d83d6253714",
            "b67be6b398d84494a7d1461e25853299",
            "9e2397a023c842bd838e9ebc978da3d4",
            "3fb84bc07e444d048f0437cee3436ce9",
            "81b404fb803440039a46614c1709721e",
            "ae1df3d2189f42bcbc367d21845956e6",
            "ed4563a699ea42b3837ebcbed3970b45",
            "13e417e8ca1f421887e1feb5fc470f68",
            "e17e3c4028ce48e799054c2aa757e5ab",
            "9f0adc1fac064d0f98b680bcdf8abf08",
            "7e75321e4c3a4cd597a0e293449da019",
            "5fe055b871024842815df970352d2d0a",
            "06f6b32a6c414c3ca22f62244d6e0927"
          ]
        },
        "outputId": "0565afba-f52b-43ae-f7b4-e100318b2f14"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/7.94k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6bd57b15f4e047589ebb799e57878973"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "train-00000-of-00001.parquet:   0%|          | 0.00/2.31M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fe25cd0ed6524223b74847ef5543c708"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "test-00000-of-00001.parquet:   0%|          | 0.00/419k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d3968da19af44c549c654eef4f8723ac"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/7473 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ba77a2d1aa4e46bc8324bcc5c6703a84"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/1319 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "16630f7161ce41e2b5f03be15e4a8be9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/7473 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7fdb99e1c4e34991a2de9f7bb994cd9b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1319 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9e2397a023c842bd838e9ebc978da3d4"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "ds = load_dataset(\"openai/gsm8k\", \"main\")\n",
        "\n",
        "\n",
        "def process_dataset(sample):\n",
        "    conversations = [\n",
        "        {\"role\": \"question\", \"content\":sample[\"question\"]},\n",
        "        {\"role\": \"answer\",\"content\":sample[\"answer\"]},\n",
        "    ]\n",
        "    return {\"messages\":conversations}\n",
        "\n",
        "\n",
        "ds = ds.map(process_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lV6Mq7n6pH23",
        "outputId": "e7f895b3-d264-41c1-ad6a-d9216d3fbedc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['question', 'answer', 'messages'],\n",
            "        num_rows: 7473\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['question', 'answer', 'messages'],\n",
            "        num_rows: 1319\n",
            "    })\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds[\"train\"][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vw6PNK6ppLTy",
        "outputId": "ad2ece70-0c48-42ca-fc8c-751e07e26d90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': 'Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?',\n",
              " 'answer': 'Natalia sold 48/2 = <<48/2=24>>24 clips in May.\\nNatalia sold 48+24 = <<48+24=72>>72 clips altogether in April and May.\\n#### 72',\n",
              " 'messages': [{'content': 'Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?',\n",
              "   'role': 'question'},\n",
              "  {'content': 'Natalia sold 48/2 = <<48/2=24>>24 clips in May.\\nNatalia sold 48+24 = <<48+24=72>>72 clips altogether in April and May.\\n#### 72',\n",
              "   'role': 'answer'}]}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlXCuRKotFlu"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "This notebook demonstrated how to apply chat templates to different models, `SmolLM2`. By structuring interactions with chat templates, we can ensure that AI models provide consistent and contextually relevant responses.\n",
        "\n",
        "In the exercise you tried out converting a dataset into chatml format. Luckily, TRL will do this for you, but it's useful to understand what's going on under the hood."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}