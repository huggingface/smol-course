{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**I trained the SmolLM2-135M model to answer data science specific questions using soufyane/DATA_SCIENCE_QA dataset from hugging face.**","metadata":{"execution":{"iopub.status.busy":"2024-12-17T20:10:40.705371Z","iopub.execute_input":"2024-12-17T20:10:40.705849Z","iopub.status.idle":"2024-12-17T20:10:50.634869Z","shell.execute_reply.started":"2024-12-17T20:10:40.705818Z","shell.execute_reply":"2024-12-17T20:10:50.633829Z"}}},{"cell_type":"code","source":"!pip install transformers datasets trl huggingface_hub","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# Authenticate to Hugging Face\nfrom huggingface_hub import login\n\nlogin()\n# for convenience you can create an environment variable containing your hub token as HF_TOKEN","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T20:11:10.693168Z","iopub.execute_input":"2024-12-17T20:11:10.693469Z","iopub.status.idle":"2024-12-17T20:11:10.945197Z","shell.execute_reply.started":"2024-12-17T20:11:10.693440Z","shell.execute_reply":"2024-12-17T20:11:10.944398Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8224f39b8aa34bcaa78e483b6d2a2869"}},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"# Import necessary libraries\n\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\n\nfrom datasets import load_dataset\n\nfrom trl import SFTConfig, SFTTrainer, setup_chat_format\n\nimport torch\n\n\n\ndevice = (\n\n    \"cuda\"\n\n    if torch.cuda.is_available()\n\n    else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n\n)\n\n\n\n# Load the model and tokenizer\n\nmodel_name = \"HuggingFaceTB/SmolLM2-135M\"\n\nmodel = AutoModelForCausalLM.from_pretrained(\n\n    pretrained_model_name_or_path=model_name\n\n).to(device)\n\ntokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=model_name)\n\n\n\n# Set up the chat format\n\nmodel, tokenizer = setup_chat_format(model=model, tokenizer=tokenizer)\n\n\n\n# Set our name for the finetune to be saved &/ uploaded to\n\nfinetune_name = \"SmolLM2-SFT-DSQA\"\n\nfinetune_tags = [\"smol-lm2-135M\", \"datascience-qa\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T20:11:22.087422Z","iopub.execute_input":"2024-12-17T20:11:22.087802Z","iopub.status.idle":"2024-12-17T20:11:52.791006Z","shell.execute_reply.started":"2024-12-17T20:11:22.087770Z","shell.execute_reply":"2024-12-17T20:11:52.790048Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/704 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c28e5abd86cd4c19a8958267612a3818"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/269M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6aa0b4595ef9488fbd28c652af083313"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9f566b381f94b4caff06dfaa7a0618c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/3.66k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c042fd2c22314a28bd8c8c3787db593c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/801k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9802136c90947af9eca7e1703c22e21"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"478e0ccd2f8a42a0bfdc1bdd92be242b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.10M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"edbb8d30db5e4a1eb50aa8b5adfd0d52"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/831 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"439c451a0ea141a3bde393745cd9ca20"}},"metadata":{}}],"execution_count":3},{"cell_type":"markdown","source":"# Generate with the base model\n\n\n\nHere we will try out the base model which does not have a chat template. ","metadata":{}},{"cell_type":"code","source":"# Let's test the base model before training\n\nprompt = \"Explain a general data science project lifecycle\"\n\n\nmessages = [{\"role\": \"user\", \"content\": prompt}]\n\nformatted_prompt = tokenizer.apply_chat_template(messages, tokenize=False)\n\n\n\n# Generate response\n\ninputs = tokenizer(formatted_prompt, return_tensors=\"pt\").to(device)\n\noutputs = model.generate(**inputs, max_new_tokens=100)\n\nprint(\"Before training:\")\n\nprint(tokenizer.decode(outputs[0], skip_special_tokens=True))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T20:13:14.698859Z","iopub.execute_input":"2024-12-17T20:13:14.699517Z","iopub.status.idle":"2024-12-17T20:13:18.645399Z","shell.execute_reply.started":"2024-12-17T20:13:14.699482Z","shell.execute_reply":"2024-12-17T20:13:18.644506Z"}},"outputs":[{"name":"stdout","text":"Before training:\nuser\nExplain a general data science project lifecycle\nExplain a general data science project lifecycle\nExplain a general data science project lifecycle\nExplain a general data science project lifecycle\nExplain a general data science project lifecycle\nExplain a general data science project lifecycle\nExplain a general data science project lifecycle\nExplain a general data science project lifecycle\nExplain a general data science project lifecycle\nExplain a general data science project lifecycle\nExplain a general data science project lifecycle\nExplain a general data science project lifecycle\nExplain a general data science project lifecycle\nExplain a general data\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"## Dataset Preparation\n\n\n\nWe will load a sample dataset and format it for training. The dataset should be structured with input-output pairs, where each input is a prompt and the output is the expected response from the model.\n\n\n\n**TRL will format input messages based on the model's chat templates.** They need to be represented as a list of dictionaries with the keys: `role` and `content`,.","metadata":{}},{"cell_type":"code","source":"# Load a sample dataset\n\nfrom datasets import load_dataset\n\n\nds = load_dataset(path=\"soufyane/DATA_SCIENCE_QA\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T20:13:21.542035Z","iopub.execute_input":"2024-12-17T20:13:21.542336Z","iopub.status.idle":"2024-12-17T20:13:24.149295Z","shell.execute_reply.started":"2024-12-17T20:13:21.542311Z","shell.execute_reply":"2024-12-17T20:13:24.148434Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"data (1).csv:   0%|          | 0.00/391k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9bdfa34b505b4cb48e9a55b80ef575d0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/1070 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e1523abbc7bc45f8b8d8598dbb3c6eea"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"# TODO: 🦁 If your dataset is not in a format that TRL can convert to the chat template, you will need to process it. Refer to the [module](../chat_templates.md)\ndef process_dataset(sample):\n\n    # use the tokenizer's method to apply the chat template\n    message_formatted = [\n        {\"role\": 'user', \"content\": sample['Question']},\n        {\"role\": 'assistant', \"content\": sample['Answer']},\n    ]\n    sample['messages'] = message_formatted\n    return sample\n\nds = ds.map(process_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T20:13:29.105530Z","iopub.execute_input":"2024-12-17T20:13:29.105918Z","iopub.status.idle":"2024-12-17T20:13:29.195646Z","shell.execute_reply.started":"2024-12-17T20:13:29.105886Z","shell.execute_reply":"2024-12-17T20:13:29.194791Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1070 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"358279ca2e7c49c68a6d6f796705d9df"}},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"ds = ds['train'].train_test_split(test_size=0.3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T20:13:32.103872Z","iopub.execute_input":"2024-12-17T20:13:32.104208Z","iopub.status.idle":"2024-12-17T20:13:32.118931Z","shell.execute_reply.started":"2024-12-17T20:13:32.104177Z","shell.execute_reply":"2024-12-17T20:13:32.118072Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"ds['train'][0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T20:13:39.036134Z","iopub.execute_input":"2024-12-17T20:13:39.036806Z","iopub.status.idle":"2024-12-17T20:13:39.045042Z","shell.execute_reply.started":"2024-12-17T20:13:39.036773Z","shell.execute_reply":"2024-12-17T20:13:39.044301Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"{'Unnamed: 0': 525,\n 'Question': 'Summarize the key idea of survival analysis briefly.',\n 'Answer': 'Survival analysis involves studying the duration until specific events happen, such as death or failure, and modeling the associated risks or probabilities over time. It accounts for censoring, where events are not observed for all subjects, and employs techniques like Kaplan-Meier estimation and Cox proportional hazards regression to analyze event times and factors influencing event occurrence.',\n 'messages': [{'content': 'Summarize the key idea of survival analysis briefly.',\n   'role': 'user'},\n  {'content': 'Survival analysis involves studying the duration until specific events happen, such as death or failure, and modeling the associated risks or probabilities over time. It accounts for censoring, where events are not observed for all subjects, and employs techniques like Kaplan-Meier estimation and Cox proportional hazards regression to analyze event times and factors influencing event occurrence.',\n   'role': 'assistant'}]}"},"metadata":{}}],"execution_count":8},{"cell_type":"markdown","source":"## Configuring the SFTTrainer\n\n\n\nThe `SFTTrainer` is configured with various parameters that control the training process. These include the number of training steps, batch size, learning rate, and evaluation strategy. Adjust these parameters based on your specific requirements and computational resources.","metadata":{}},{"cell_type":"code","source":"# Configure the SFTTrainer\n\nsft_config = SFTConfig(\n\n    output_dir=\"./sft_output\",\n\n    # 500 would have worked for this one\n    max_steps=1000,  # Adjust based on dataset size and desired training duration\n\n    per_device_train_batch_size=4,  # Set according to your GPU memory capacity\n\n    learning_rate=5e-5,  # Common starting point for fine-tuning\n\n    logging_steps=10,  # Frequency of logging training metrics\n\n    save_steps=100,  # Frequency of saving model checkpoints\n\n    evaluation_strategy=\"steps\",  # Evaluate the model at regular intervals\n\n    eval_steps=50,  # Frequency of evaluation\n\n    use_mps_device=(\n\n        True if device == \"mps\" else False\n\n    ),  # Use MPS for mixed precision training\n\n    hub_model_id=finetune_name,  # Set a unique name for your model\n\n)\n\n\n\n# Initialize the SFTTrainer\n\ntrainer = SFTTrainer(\n\n    model=model,\n\n    args=sft_config,\n\n    train_dataset=ds[\"train\"],\n\n    tokenizer=tokenizer,\n\n    eval_dataset=ds[\"test\"],\n\n)\n\n\n\n# TODO: 🦁 🐕 align the SFTTrainer params with your chosen dataset. For example, if you are using the `bigcode/the-stack-smol` dataset, you will need to choose the `content` column`","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T20:13:41.994188Z","iopub.execute_input":"2024-12-17T20:13:41.995172Z","iopub.status.idle":"2024-12-17T20:13:42.485705Z","shell.execute_reply.started":"2024-12-17T20:13:41.995135Z","shell.execute_reply":"2024-12-17T20:13:42.484959Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/tmp/ipykernel_23/3767605764.py:35: FutureWarning: `tokenizer` is deprecated and removed starting from version 0.16.0 for `SFTTrainer.__init__`. Use `processing_class` instead.\n  trainer = SFTTrainer(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/749 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95b252ef434d47c99537a52d457901fe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/321 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d0113d79f96f4102bbe5143936de88dc"}},"metadata":{}},{"name":"stderr","text":"max_steps is given, it will override any value given in num_train_epochs\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"## Training the Model\n\n\n\nWith the trainer configured, we can now proceed to train the model. The training process will involve iterating over the dataset, computing the loss, and updating the model's parameters to minimize this loss.","metadata":{}},{"cell_type":"code","source":"# Train the model\n\ntrainer.train()\n\n# Save the model\ntrainer.save_model(f\"./{finetune_name}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T20:13:46.142070Z","iopub.execute_input":"2024-12-17T20:13:46.142423Z","iopub.status.idle":"2024-12-17T20:17:27.073028Z","shell.execute_reply.started":"2024-12-17T20:13:46.142390Z","shell.execute_reply":"2024-12-17T20:17:27.072024Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.18.7"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241217_201355-e9q4ea19</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/avisha-bhiryani/huggingface/runs/e9q4ea19' target=\"_blank\">./sft_output</a></strong> to <a href='https://wandb.ai/avisha-bhiryani/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/avisha-bhiryani/huggingface' target=\"_blank\">https://wandb.ai/avisha-bhiryani/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/avisha-bhiryani/huggingface/runs/e9q4ea19' target=\"_blank\">https://wandb.ai/avisha-bhiryani/huggingface/runs/e9q4ea19</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1000/1000 03:28, Epoch 5/6]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>2.030900</td>\n      <td>1.918021</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>1.760900</td>\n      <td>1.869897</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>1.672700</td>\n      <td>1.843704</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>1.391400</td>\n      <td>1.840126</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>1.382000</td>\n      <td>1.864417</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>1.351500</td>\n      <td>1.864695</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>1.388100</td>\n      <td>1.855685</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>1.057800</td>\n      <td>1.917605</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>1.031000</td>\n      <td>1.944387</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>1.021100</td>\n      <td>1.941496</td>\n    </tr>\n    <tr>\n      <td>550</td>\n      <td>1.115700</td>\n      <td>1.945912</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.810200</td>\n      <td>2.050892</td>\n    </tr>\n    <tr>\n      <td>650</td>\n      <td>0.733300</td>\n      <td>2.072941</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>0.798900</td>\n      <td>2.084559</td>\n    </tr>\n    <tr>\n      <td>750</td>\n      <td>0.761300</td>\n      <td>2.082744</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>0.612600</td>\n      <td>2.189297</td>\n    </tr>\n    <tr>\n      <td>850</td>\n      <td>0.625300</td>\n      <td>2.187964</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>0.628800</td>\n      <td>2.197758</td>\n    </tr>\n    <tr>\n      <td>950</td>\n      <td>0.509700</td>\n      <td>2.209756</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.525700</td>\n      <td>2.228873</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"trainer.push_to_hub(tags=finetune_tags)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T20:19:33.614768Z","iopub.execute_input":"2024-12-17T20:19:33.615495Z","iopub.status.idle":"2024-12-17T20:19:56.832368Z","shell.execute_reply.started":"2024-12-17T20:19:33.615453Z","shell.execute_reply":"2024-12-17T20:19:56.831599Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Upload 3 LFS files:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c673c80e07dd43e580f532280832926a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"events.out.tfevents.1734466426.e97a5d704eae.23.0:   0%|          | 0.00/32.4k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d14b249cda184d1cbc67e3038d29dd18"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/538M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de85bae25d84487783b98c41803f0a39"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"training_args.bin:   0%|          | 0.00/5.56k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ad7f2a8d2bc4825a927baad90634909"}},"metadata":{}},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/Avibhi/SmolLM2-SFT-DSQA/commit/732fdaa1ad0b45b449946c99ee75dce7ee1080b5', commit_message='End of training', commit_description='', oid='732fdaa1ad0b45b449946c99ee75dce7ee1080b5', pr_url=None, repo_url=RepoUrl('https://huggingface.co/Avibhi/SmolLM2-SFT-DSQA', endpoint='https://huggingface.co', repo_type='model', repo_id='Avibhi/SmolLM2-SFT-DSQA'), pr_revision=None, pr_num=None)"},"metadata":{}}],"execution_count":11},{"cell_type":"markdown","source":"<div style='background-color: lightblue; padding: 10px; border-radius: 5px; margin-bottom: 20px; color:black'>\n\n    <h2 style='margin: 0;color:blue'>Bonus Exercise: Generate with fine-tuned model</h2>\n\n    <p>🐕 Use the fine-tuned to model generate a response, just like with the base example..</p>\n\n</div>","metadata":{}},{"cell_type":"code","source":"# Test the fine-tuned model on the same prompt\n\n\nprompt = \"Explain a general data science project lifecycle\"\nmessages = [{\"role\": \"user\", \"content\": prompt}]\nformatted_prompt = tokenizer.apply_chat_template(messages, tokenize=False)\n\n\n# Generate response\n\ninputs = tokenizer(formatted_prompt, return_tensors=\"pt\").to(device)\n\n\n# finetuned model \nmodel_name = 'Avibhi/SmolLM2-SFT-DSQA'\n\nmodel = AutoModelForCausalLM.from_pretrained(\n\n    pretrained_model_name_or_path=model_name\n\n).to(device)\n\noutputs = model.generate(**inputs, max_new_tokens=100)\n\nprint(\"After training:\")\n\nprint(tokenizer.decode(outputs[0], skip_special_tokens=True))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T20:22:44.157104Z","iopub.execute_input":"2024-12-17T20:22:44.157981Z","iopub.status.idle":"2024-12-17T20:23:00.812057Z","shell.execute_reply.started":"2024-12-17T20:22:44.157947Z","shell.execute_reply":"2024-12-17T20:23:00.811151Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/812 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47dc2063a0af4322bd9d20aa10e03569"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/538M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e6fb844ff454a53817c0f4059211f36"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/132 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f9d56cdda1249e38d891403dd460057"}},"metadata":{}},{"name":"stdout","text":"After training:\nuser\nExplain a general data science project lifecycle\nassistant\nA general data science project lifecycle includes stages from defining business objectives to monitoring and managing data. Initially, business needs and objectives need to be defined. Data collection and organization are established. Data preparation includes cleaning and transforming data, and preparing it for analysis. Data storage and preservation are also considered. Data analysis begins with data analysis tools and techniques. Data interpretation and decision-making are carried out using analytical tools and models. Data management and storage are finalized. Data utilization and stewardship is completed\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# Few other examples\nprompt = \"Explain EDA in 3 sentences\"\n\n# Format with template\n\nmessages = [{\"role\": \"user\", \"content\": prompt}]\n\nformatted_prompt = tokenizer.apply_chat_template(messages, tokenize=False)\n\n# Generate response\n\ninputs = tokenizer(formatted_prompt, return_tensors=\"pt\").to(device)\n\noutputs = model.generate(**inputs, max_new_tokens=200)\n\nprint(tokenizer.decode(outputs[0], skip_special_tokens=True))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T20:25:17.855459Z","iopub.execute_input":"2024-12-17T20:25:17.855851Z","iopub.status.idle":"2024-12-17T20:25:23.513457Z","shell.execute_reply.started":"2024-12-17T20:25:17.855815Z","shell.execute_reply":"2024-12-17T20:25:23.512391Z"}},"outputs":[{"name":"stdout","text":"user\nExplain EDA in 3 sentences\nassistant\nEDA, or data analysis, is the process of looking at data to understand its meaning and how it fits together. It involves tasks like data cleaning, data visualization, and data analysis to extract insights and make informed decisions from the data. EDA is essential for ensuring data quality, ensuring data is available for analysis, and making informed decisions based on the data. It's like being a detective who solves data problems!\n\nEDA is crucial in various industries, including finance, marketing, and government, to extract valuable insights from data and make decisions that affect businesses and lives. By analyzing data, EDA helps businesses achieve their goals and objectives by understanding data insights and making strategic decisions. Without EDA, data analysis would be a guessing game, and businesses would struggle to make sense of the data they're given.\n\nEDA is a critical component of data management and analysis, contributing to the development and utilization of data in society. Without EDA, businesses and\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"## 💐 You're done!\n\n\n\nThis notebook provided a step-by-step guide to fine-tuning the `HuggingFaceTB/SmolLM2-135M` model using the `SFTTrainer`. By following these steps, you can adapt the model to perform specific tasks more effectively. If you want to carry on working on this course, here are steps you could try out:\n\n\n\n- Try this notebook on a harder difficulty\n\n- Review a colleagues PR\n\n- Improve the course material via an Issue or PR.","metadata":{}}]}